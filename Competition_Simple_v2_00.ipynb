{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hw_version": "1.0.0",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Competition Simple v2.00.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFl1JjaO6f4s",
        "colab_type": "text"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ku6Hztk9LME",
        "colab_type": "text"
      },
      "source": [
        "This notebook summarizes the final project of the course. The following versions of packages are used in this work.\n",
        "\n",
        "numpy 1.18.4\n",
        "\n",
        "pandas 1.0.3\n",
        "\n",
        "scipy 1.4.1\n",
        "\n",
        "sklearn 0.22.2.post1\n",
        "\n",
        "lightgbm 2.2.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaRYVCq2EHzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3b160ff6-ca74-457b-8d28-476e3094e7ac"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from itertools import product\n",
        "import sklearn.model_selection\n",
        "\n",
        "import sklearn\n",
        "import scipy.sparse \n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "import pickle\n",
        "\n",
        "for p in [np, pd, scipy, sklearn, lightgbm]:\n",
        "    print (p.__name__, p.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy 1.18.4\n",
            "pandas 1.0.3\n",
            "scipy 1.4.1\n",
            "sklearn 0.22.2.post1\n",
            "lightgbm 2.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2DVFDCA-GOh",
        "colab_type": "text"
      },
      "source": [
        "Read the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig1mG6e_EHzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions    = pd.read_csv('sales_train.csv.zip')\n",
        "items           = pd.read_csv('items.csv.zip')\n",
        "item_categories = pd.read_csv('item_categories.csv')\n",
        "shops           = pd.read_csv('shops.csv')\n",
        "test           = pd.read_csv('test.csv.zip')\n",
        "submission           = pd.read_csv('sample_submission.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPSstVMiBzd2",
        "colab_type": "text"
      },
      "source": [
        "#EDA\n",
        "\n",
        "This section looks at some of the features available on the competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTQaQTZmK8xh",
        "colab_type": "text"
      },
      "source": [
        "# Feature generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27PdgoBLsnKB",
        "colab_type": "text"
      },
      "source": [
        "This code snippet downcasts the data types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XSNku3ksueJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows', 600)\n",
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "def downcast_dtypes(df):\n",
        "    '''\n",
        "        Changes column types in the dataframe: \n",
        "                \n",
        "                `float64` type to `float32`\n",
        "                `int64`   type to `int32`\n",
        "    '''\n",
        "    \n",
        "    # Select columns to downcast\n",
        "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
        "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
        "    \n",
        "    # Downcast\n",
        "    df[float_cols] = df[float_cols].astype(np.float32)\n",
        "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf_NP0Eys3OG",
        "colab_type": "text"
      },
      "source": [
        "Generating some features (the monthly total sales for each item, total sales of each store, and total sales for each item in each store)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuLxUnQNLp5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2822fe4c-06dc-493b-ab9e-07579790f08d"
      },
      "source": [
        "# Create \"grid\" with columns\n",
        "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
        "\n",
        "# For every month we create a grid from all shops/items combinations from that month\n",
        "grid = [] \n",
        "for block_num in transactions['date_block_num'].unique():\n",
        "    cur_shops = transactions.loc[transactions['date_block_num'] == block_num, 'shop_id'].unique()\n",
        "    cur_items = transactions.loc[transactions['date_block_num'] == block_num, 'item_id'].unique()\n",
        "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
        "\n",
        "# Turn the grid into a dataframe\n",
        "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
        "\n",
        "# Groupby data to get shop-item-month aggregates\n",
        "gb = transactions.groupby(index_cols,as_index=False).item_cnt_day.sum()\n",
        "gb.rename(columns={'item_cnt_day':'trg'},inplace=True)\n",
        "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
        "\n",
        "# Same as above but with shop-month aggregates\n",
        "gb = transactions.groupby(['shop_id', 'date_block_num'],as_index=False).item_cnt_day.sum()\n",
        "gb.rename(columns={'item_cnt_day':'s_mn'},inplace=True)\n",
        "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
        "\n",
        "# Same as above but with item-month aggregates\n",
        "gb = transactions.groupby(['item_id', 'date_block_num'],as_index=False).item_cnt_day.sum()\n",
        "gb.rename(columns={'item_cnt_day':'i_mn'},inplace=True)\n",
        "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
        "\n",
        "# Downcast dtypes from 64 to 32 bit to save memory\n",
        "all_data = downcast_dtypes(all_data)\n",
        "del grid, gb \n",
        "gc.collect();\n",
        "print(all_data.head())\n",
        "print(all_data.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   shop_id  item_id  date_block_num  trg    s_mn  i_mn\n",
            "0       59    22154               0  1.0  2017.0  18.0\n",
            "1       59     2552               0  0.0  2017.0   0.0\n",
            "2       59     2554               0  0.0  2017.0   1.0\n",
            "3       59     2555               0  0.0  2017.0   2.0\n",
            "4       59     2564               0  0.0  2017.0   5.0\n",
            "          shop_id  item_id  date_block_num  trg    s_mn  i_mn\n",
            "10913845       21     7635              33  0.0  1912.0   1.0\n",
            "10913846       21     7638              33  0.0  1912.0   1.0\n",
            "10913847       21     7640              33  0.0  1912.0   1.0\n",
            "10913848       21     7632              33  0.0  1912.0   1.0\n",
            "10913849       21     7440              33  0.0  1912.0   1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm-euzAOyDYq",
        "colab_type": "text"
      },
      "source": [
        "Taking the Lag (1 month before, 2 months before, 3 months before, 6 months before and 1 year before) of the above mentioned features (target, shop_target, item_target). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4ZczyNyeVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9541a5fb-e0f0-4a46-a0b2-4e0d6e965bcb"
      },
      "source": [
        "# List of columns that we will use to create lags\n",
        "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
        "print(cols_to_rename)\n",
        "shift_range = [1, 2, 3, 4, 5, 6, 12]\n",
        "\n",
        "for month_shift in shift_range:\n",
        "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
        "    \n",
        "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
        "    \n",
        "    foo = lambda x: '{}_l_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
        "    train_shift = train_shift.rename(columns=foo)\n",
        "\n",
        "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
        "\n",
        "del train_shift\n",
        "\n",
        "# Don't use old data from year 2013\n",
        "all_data = all_data[all_data['date_block_num'] >= 12] \n",
        "\n",
        "# List of all lagged features\n",
        "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
        "# We will drop these at fitting stage\n",
        "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
        "\n",
        "# Category for each item\n",
        "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
        "\n",
        "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
        "all_data = downcast_dtypes(all_data)\n",
        "# print(to_drop_cols)\n",
        "# print(all_data.head(10))\n",
        "# print(all_data.tail(10))\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i_mn', 's_mn', 'trg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUGOB6Rglvr7",
        "colab_type": "text"
      },
      "source": [
        "##Adding mean encoding for category values\n",
        "In this section we add the mean encoding for items based on item categories. K-fold mean encoding is used to generate these values. The mean encoding of each item category for each month is generated. Similar to the previousfeatures lagged mean encoding for 1 month, 2 month, 3 months, 6 months and 12 months is added to the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_dhVm79G9la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14d5b9c9-1a22-47ae-95f4-eaba2a743ad3"
      },
      "source": [
        "# YOUR CODE GOES HERE\n",
        "\n",
        "Folds=sklearn.model_selection.KFold(5,shuffle=False)\n",
        "#print(Folds[1])\n",
        "\n",
        "for train_index, test_index in Folds.split(all_data):\n",
        "    X_tr, X_val = all_data.iloc[train_index], all_data.iloc[test_index]\n",
        "    all_data.loc[all_data.index[test_index],'item_cat_target_enc']=X_val['item_category_id'].map(X_tr.groupby('item_category_id')['trg'].mean())\n",
        "    #item_id_target_mean = all_data.iloc(train_index).groupby('item_id').target.mean()    \n",
        "\n",
        "all_data['item_cat_target_enc'].fillna(0.3343, inplace=True)\n",
        "item_id_target_mean = all_data.groupby('item_category_id').item_cat_target_enc.mean()\n",
        "all_data['item_cat_target_enc'] = all_data['item_category_id'].map(item_id_target_mean)\n",
        "\n",
        "# Fill NaNs\n",
        " # Print correlation\n",
        "encoded_feature = all_data['item_cat_target_enc'].values\n",
        "# You will need to compute correlation like that\n",
        "corr = np.corrcoef(all_data['trg'].values, encoded_feature)[0][1]\n",
        "print(corr)\n",
        "all_data = downcast_dtypes(all_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4078919456341599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6tTTkIAS4fs",
        "colab_type": "text"
      },
      "source": [
        "##Seperating the validation and training sets\n",
        "Here, the data from the final month on the training set is used as the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J82wxMgS-Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data =  all_data.drop(['item_cat_target_enc'], axis=1)\n",
        "#all_data =  all_data.drop(['item_category_id'], axis=1)\n",
        "X_train = all_data.loc[all_data['date_block_num'] <  33].drop(to_drop_cols, axis=1)\n",
        "#X_train=X_train.drop(['item_cat_target_enc'],axis=1)\n",
        "X_test =  all_data.loc[all_data['date_block_num']== 33].drop(to_drop_cols, axis=1)\n",
        "#X_test=X_test.drop(['item_cat_target_enc'],axis=1)\n",
        "\n",
        "y_train = all_data.loc[all_data['date_block_num'] <  33, 'trg'].values\n",
        "y_test =  all_data.loc[all_data['date_block_num'] == 33, 'trg'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpv5Y5RBF1z9",
        "colab_type": "text"
      },
      "source": [
        "##Generating the same features for the final data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlSV7c6VDMxh",
        "colab_type": "text"
      },
      "source": [
        "Here, setting up the final features for the unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDrgskldDgIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "718ae21c-c281-411d-d67b-adc71fa50d19"
      },
      "source": [
        "test['date_block_num']=34\n",
        "#print(test.head())\n",
        "\n",
        "shift_range = [1, 2, 3,4,5, 6, 12]\n",
        "\n",
        "for month_shift in shift_range:\n",
        "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
        "    \n",
        "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
        "    \n",
        "    foo = lambda x: '{}_l_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
        "    train_shift = train_shift.rename(columns=foo)\n",
        "\n",
        "    test = pd.merge(test, train_shift, on=index_cols, how='left').fillna(0)\n",
        "\n",
        "del train_shift\n",
        "\n",
        "# Category for each item\n",
        "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
        "\n",
        "test = pd.merge(test, item_category_mapping, how='left', on='item_id')\n",
        "test = downcast_dtypes(test)\n",
        "#test['item_cat_target_enc'] = all_data['item_category_id'].map(item_id_target_mean)\n",
        "\n",
        "# print(test.head())\n",
        "test_final =  test.drop(['date_block_num','ID'], axis=1)\n",
        "# print(test_final.head())\n",
        "print(test_final.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(214200, 24)\n",
            "(6186922, 24)\n",
            "(238172, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP0T0UYtPAHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "fb75c24e-ed70-4513-da37-dd644f5dbcf6"
      },
      "source": [
        "print(test_final.columns)\n",
        "print(X_train.columns)\n",
        "X=X_train.append(X_test, ignore_index = True) \n",
        "y=np.append(y_train,y_test)\n",
        "print(to_drop_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['shop_id', 'item_id', 'i_mn_l_1', 's_mn_l_1', 'trg_l_1', 'i_mn_l_2',\n",
            "       's_mn_l_2', 'trg_l_2', 'i_mn_l_3', 's_mn_l_3', 'trg_l_3', 'i_mn_l_4',\n",
            "       's_mn_l_4', 'trg_l_4', 'i_mn_l_5', 's_mn_l_5', 'trg_l_5', 'i_mn_l_6',\n",
            "       's_mn_l_6', 'trg_l_6', 'i_mn_l_12', 's_mn_l_12', 'trg_l_12',\n",
            "       'item_category_id'],\n",
            "      dtype='object')\n",
            "Index(['shop_id', 'item_id', 'i_mn_l_1', 's_mn_l_1', 'trg_l_1', 'i_mn_l_2',\n",
            "       's_mn_l_2', 'trg_l_2', 'i_mn_l_3', 's_mn_l_3', 'trg_l_3', 'i_mn_l_4',\n",
            "       's_mn_l_4', 'trg_l_4', 'i_mn_l_5', 's_mn_l_5', 'trg_l_5', 'i_mn_l_6',\n",
            "       's_mn_l_6', 'trg_l_6', 'i_mn_l_12', 's_mn_l_12', 'trg_l_12',\n",
            "       'item_category_id'],\n",
            "      dtype='object')\n",
            "['trg', 's_mn', 'i_mn', 'date_block_num']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yasHx54pMzAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_final.to_csv('test_final.csv',index=False)\n",
        "all_data.to_csv('all_data.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti7RJa-VGb4v",
        "colab_type": "text"
      },
      "source": [
        "#Single Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJYjzd3GCfV",
        "colab_type": "text"
      },
      "source": [
        "## Training the Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_yYE3pFDudi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1613a678-8e32-4393-8b08-810b4b55f852"
      },
      "source": [
        "\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train.values, y_train)\n",
        "pred_lr = lr.predict(X_test.values)\n",
        "\n",
        "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))\n",
        "print('Test MSE for linreg is %f' % mean_squared_error(y_test, pred_lr)**0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test R-squared for linreg is 0.249171\n",
            "Test MSE for linreg is 4.629506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBoNwa7ORRKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db03c18f-8a1f-41c1-8fbe-f6051a9ccba8"
      },
      "source": [
        "\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "X_lr = sc_X.fit_transform(X_train)\n",
        "X_t_lr = sc_X.fit_transform(X_test)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_lr, y_train)\n",
        "pred_lr = lr.predict(X_t_lr)\n",
        "\n",
        "print('Test R-squared for linreg is %f' % r2_score(y_test, pred_lr))\n",
        "print('Test MSE for linreg is %f' % mean_squared_error(y_test, pred_lr)**0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test R-squared for linreg is 0.274102\n",
            "Test MSE for linreg is 4.551994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_3ZBbqhS7QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4f391dd8-435d-4027-cf7e-258b7a4072f7"
      },
      "source": [
        "lr.fit(sc_X.fit_transform(X), y)\n",
        "final_pred_lr = lr.predict(sc_X.fit_transform(test_final))\n",
        "\n",
        "submission['item_cnt_month']=final_pred_lr.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('LR_single.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID  item_cnt_month\n",
            "0   0        0.680842\n",
            "1   1        0.145837\n",
            "2   2        1.081187\n",
            "3   3        0.341886\n",
            "4   4        0.161811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa9qhhsCD7qk",
        "colab_type": "text"
      },
      "source": [
        "The leaderboard score with this solution: 1.05954"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gZHZ6vYn0t_Y"
      },
      "source": [
        "## Training the LGB Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjjV4gIWNTPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1ecfcce-827a-4ef8-90c5-a21007f57fb4"
      },
      "source": [
        "lgb_params = {\n",
        "               'feature_fraction': 0.75,\n",
        "               'metric': 'rmse',\n",
        "               'nthread':1, \n",
        "               'min_data_in_leaf': 2**7, \n",
        "               'bagging_fraction': 0.75, \n",
        "               'learning_rate': 0.03, \n",
        "               'objective': 'mse', \n",
        "               'bagging_seed': 2**7, \n",
        "               'num_leaves': 2**7,\n",
        "               'bagging_freq':1,\n",
        "               'verbose':0 \n",
        "              }\n",
        "\n",
        "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
        "pred_lgb = model.predict(X_test)\n",
        "\n",
        "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))\n",
        "print('Test MSE for LightGBM is %f' % mean_squared_error(y_test, pred_lgb)**0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test R-squared for LightGBM is 0.270185\n",
            "Test MSE for LightGBM is 20.832469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrVfOwKtTCxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2f48405f-728c-4b21-e29a-99dab3040add"
      },
      "source": [
        "model = lgb.train(lgb_params, lgb.Dataset(X, label=y), 200)\n",
        "final_pred_lgb = model.predict(test_final)\n",
        "submission['item_cnt_month']=final_pred_lgb.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('LGB_single.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID  item_cnt_month\n",
            "0   0        0.391065\n",
            "1   1        0.296546\n",
            "2   2        0.862037\n",
            "3   3        0.209695\n",
            "4   4        0.065971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G7J8ig1EElh1"
      },
      "source": [
        "The leaderboard score with this solution: 0.97665"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAd47xO5U4Oh",
        "colab_type": "text"
      },
      "source": [
        "## Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMEuQ1h8Cfp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "145f0e54-39a8-4c4e-9973-16fc5bfe68b5"
      },
      "source": [
        "\n",
        "sc_X = StandardScaler()\n",
        "X_nn = sc_X.fit_transform(X_train)\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(32,16), activation='relu', solver='adam', max_iter=50,early_stopping=True,verbose=1)\n",
        "mlp.fit(X_nn,y_train)\n",
        "\n",
        "pred_NN = mlp.predict(sc_X.fit_transform(X_test))\n",
        "\n",
        "print('Test R-squared for NN is %f' % r2_score(y_test, pred_NN))\n",
        "print('Test MSE for NN is %f' % mean_squared_error(y_test, pred_NN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.59986367\n",
            "Validation score: 0.456206\n",
            "Iteration 2, loss = 3.40334688\n",
            "Validation score: 0.345852\n",
            "Iteration 3, loss = 3.40445183\n",
            "Validation score: 0.451515\n",
            "Iteration 4, loss = 3.26825400\n",
            "Validation score: 0.466035\n",
            "Iteration 5, loss = 3.22748782\n",
            "Validation score: 0.482459\n",
            "Iteration 6, loss = 3.18635940\n",
            "Validation score: 0.492130\n",
            "Iteration 7, loss = 3.08349038\n",
            "Validation score: 0.489577\n",
            "Iteration 8, loss = 3.09543755\n",
            "Validation score: 0.371736\n",
            "Iteration 9, loss = 3.02243007\n",
            "Validation score: 0.315471\n",
            "Iteration 10, loss = 3.02623559\n",
            "Validation score: 0.497471\n",
            "Iteration 11, loss = 2.96499008\n",
            "Validation score: 0.457873\n",
            "Iteration 12, loss = 3.00854589\n",
            "Validation score: 0.504584\n",
            "Iteration 13, loss = 2.92191502\n",
            "Validation score: 0.497234\n",
            "Iteration 14, loss = 2.88283156\n",
            "Validation score: 0.488629\n",
            "Iteration 15, loss = 2.84664435\n",
            "Validation score: 0.516002\n",
            "Iteration 16, loss = 2.82917486\n",
            "Validation score: 0.547496\n",
            "Iteration 17, loss = 2.87043376\n",
            "Validation score: 0.501640\n",
            "Iteration 18, loss = 2.77410318\n",
            "Validation score: 0.498566\n",
            "Iteration 19, loss = 2.77913158\n",
            "Validation score: 0.526284\n",
            "Iteration 20, loss = 2.79737471\n",
            "Validation score: 0.533527\n",
            "Iteration 21, loss = 2.71808733\n",
            "Validation score: 0.495407\n",
            "Iteration 22, loss = 2.77692925\n",
            "Validation score: 0.500838\n",
            "Iteration 23, loss = 2.69344687\n",
            "Validation score: 0.563174\n",
            "Iteration 24, loss = 2.77245884\n",
            "Validation score: 0.538402\n",
            "Iteration 25, loss = 2.75120108\n",
            "Validation score: 0.553794\n",
            "Iteration 26, loss = 2.74932276\n",
            "Validation score: 0.531917\n",
            "Iteration 27, loss = 2.66762511\n",
            "Validation score: 0.528442\n",
            "Iteration 28, loss = 2.69004173\n",
            "Validation score: 0.510937\n",
            "Iteration 29, loss = 2.59601600\n",
            "Validation score: 0.422194\n",
            "Iteration 30, loss = 2.68353290\n",
            "Validation score: 0.497709\n",
            "Iteration 31, loss = 2.64622281\n",
            "Validation score: 0.533377\n",
            "Iteration 32, loss = 2.67350481\n",
            "Validation score: 0.548154\n",
            "Iteration 33, loss = 2.53095723\n",
            "Validation score: 0.491043\n",
            "Iteration 34, loss = 2.57515183\n",
            "Validation score: 0.523761\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Test R-squared for NN is 0.287743\n",
            "Test MSE for NN is 20.331272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjSp8sh-dPcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb35ac21-3757-45d8-8a28-b0474eee1187"
      },
      "source": [
        "mlp.fit(sc_X.fit_transform(X),y)\n",
        "\n",
        "final_pred_NN = mlp.predict(sc_X.fit_transform(test_final))\n",
        "\n",
        "submission['item_cnt_month']=final_pred_NN.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('NN_single.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6425094, 24)\n",
            "[ 4.  3. 14. ...  0.  0.  0.]\n",
            "Iteration 1, loss = 3.94180767\n",
            "Validation score: 0.631982\n",
            "Iteration 2, loss = 3.85987834\n",
            "Validation score: 0.643249\n",
            "Iteration 3, loss = 3.77343951\n",
            "Validation score: 0.617618\n",
            "Iteration 4, loss = 3.70162644\n",
            "Validation score: 0.616193\n",
            "Iteration 5, loss = 3.65802670\n",
            "Validation score: 0.587009\n",
            "Iteration 6, loss = 3.66178399\n",
            "Validation score: 0.619863\n",
            "Iteration 7, loss = 3.64508192\n",
            "Validation score: 0.644419\n",
            "Iteration 8, loss = 3.60187745\n",
            "Validation score: 0.630723\n",
            "Iteration 9, loss = 3.56069926\n",
            "Validation score: 0.618781\n",
            "Iteration 10, loss = 3.51997294\n",
            "Validation score: 0.609351\n",
            "Iteration 11, loss = 3.49343935\n",
            "Validation score: 0.576080\n",
            "Iteration 12, loss = 3.47338765\n",
            "Validation score: 0.615565\n",
            "Iteration 13, loss = 3.46855596\n",
            "Validation score: 0.622208\n",
            "Iteration 14, loss = 3.39340554\n",
            "Validation score: 0.637519\n",
            "Iteration 15, loss = 3.38454742\n",
            "Validation score: 0.591961\n",
            "Iteration 16, loss = 3.31814647\n",
            "Validation score: 0.635963\n",
            "Iteration 17, loss = 3.34706725\n",
            "Validation score: 0.617415\n",
            "Iteration 18, loss = 3.31352979\n",
            "Validation score: 0.664926\n",
            "Iteration 19, loss = 3.35663896\n",
            "Validation score: 0.613679\n",
            "Iteration 20, loss = 3.25995985\n",
            "Validation score: 0.623920\n",
            "Iteration 21, loss = 3.17396147\n",
            "Validation score: 0.647635\n",
            "Iteration 22, loss = 3.19946962\n",
            "Validation score: 0.602033\n",
            "Iteration 23, loss = 3.09975985\n",
            "Validation score: 0.600630\n",
            "Iteration 24, loss = 3.20509157\n",
            "Validation score: 0.463581\n",
            "Iteration 25, loss = 3.13821471\n",
            "Validation score: 0.611663\n",
            "Iteration 26, loss = 3.13666247\n",
            "Validation score: 0.591597\n",
            "Iteration 27, loss = 3.18336936\n",
            "Validation score: 0.626804\n",
            "Iteration 28, loss = 3.02353734\n",
            "Validation score: 0.612997\n",
            "Iteration 29, loss = 3.13218637\n",
            "Validation score: 0.612499\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "   ID  item_cnt_month\n",
            "0   0        0.089912\n",
            "1   1        0.089912\n",
            "2   2        0.790698\n",
            "3   3        0.263179\n",
            "4   4        1.568451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ff7fCng5EzlR"
      },
      "source": [
        "The leaderboard score with this solution: 1.00741\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAL72EDM7vKw"
      },
      "source": [
        "## Training a Support Vector Regression Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQiMouR71Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "758bf7f4-1067-4837-b02e-30e0089faf0d"
      },
      "source": [
        "\n",
        "sc_X = StandardScaler()\n",
        "X_svr = sc_X.fit_transform(X_train)\n",
        "\n",
        "\n",
        "\n",
        "svr_rbf = SVR(kernel='rbf',C=100,verbose=1,max_iter=20)\n",
        "svr_rbf.fit(X_svr,y_train)\n",
        "#5 Predicting a new result\n",
        "\n",
        "pred_SVR = svr_rbf.predict(X_train)\n",
        "pred_SVR = svr_rbf.predict(sc_X.fit_transform(X_test))\n",
        "\n",
        "print('Test R-squared for SVR is %f' % r2_score(y_test, pred_SVR))\n",
        "print('Test MSE for SVR is %f' % mean_squared_error(y_test, pred_SVR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test R-squared for SVR is -4072.593107\n",
            "Test MSE for SVR is 116280.196783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6smk-04lZBNO",
        "colab_type": "text"
      },
      "source": [
        "For some reason SVR dis not worked as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yisAa8UZH5y",
        "colab_type": "text"
      },
      "source": [
        "##Trying a kNN Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRlVYK7KZMQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "X_knn = sc_X.fit_transform(X_train)\n",
        "X_t_knn = sc_X.fit_transform(X_test)\n",
        "\n",
        "knn = neighbors.KNeighborsRegressor(n_neighbors=1, weights='distance')\n",
        "knn.fit(X_knn, y_train)\n",
        "pred_knn = knn.predict(X_t_knn)\n",
        "\n",
        "print('Test R-squared for kNN is %f' % r2_score(y_test, pred_knn))\n",
        "print('Test MSE for kNN is %f' % mean_squared_error(y_test, pred_knn)**0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDftkgIeE16h",
        "colab_type": "text"
      },
      "source": [
        "TTHis code did not worked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjOt1CXQ_QnR",
        "colab_type": "text"
      },
      "source": [
        "##XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3T_yBZ_fqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c414912-1bc2-48ba-d518-9acf7884fdc6"
      },
      "source": [
        "\n",
        "\n",
        "model = XGBRegressor(max_depth=8,n_estimators=1000,min_child_weight=100,colsample_bytree=0.8,subsample=0.8,eta=0.3,seed=42)\n",
        "\n",
        "model.fit(X_train,y_train,eval_metric=\"rmse\",eval_set=[(X_train, y_train),(X_test, y_test)],verbose=True,early_stopping_rounds = 10)\n",
        "#model.fit(X_train,y_train,eval_metric=\"rmse\",verbose=True)\n",
        "pred_xgb=model.predict(X_test)\n",
        "\n",
        "print('Test R-squared for kNN is %f' % r2_score(y_test, pred_xgb))\n",
        "print('Test MSE for kNN is %f' % mean_squared_error(y_test, pred_xgb)**0.5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[04:25:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[04:25:54] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "[0]\tvalidation_0-rmse:3.42169\tvalidation_1-rmse:5.28187\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-rmse:3.32599\tvalidation_1-rmse:5.2089\n",
            "[2]\tvalidation_0-rmse:3.23701\tvalidation_1-rmse:5.15404\n",
            "[3]\tvalidation_0-rmse:3.14569\tvalidation_1-rmse:5.09839\n",
            "[4]\tvalidation_0-rmse:3.07279\tvalidation_1-rmse:5.05398\n",
            "[5]\tvalidation_0-rmse:3.00882\tvalidation_1-rmse:5.0147\n",
            "[6]\tvalidation_0-rmse:2.95496\tvalidation_1-rmse:4.98146\n",
            "[7]\tvalidation_0-rmse:2.91499\tvalidation_1-rmse:4.95232\n",
            "[8]\tvalidation_0-rmse:2.87663\tvalidation_1-rmse:4.92764\n",
            "[9]\tvalidation_0-rmse:2.8423\tvalidation_1-rmse:4.90464\n",
            "[10]\tvalidation_0-rmse:2.81432\tvalidation_1-rmse:4.87252\n",
            "[11]\tvalidation_0-rmse:2.77922\tvalidation_1-rmse:4.85242\n",
            "[12]\tvalidation_0-rmse:2.7585\tvalidation_1-rmse:4.8276\n",
            "[13]\tvalidation_0-rmse:2.73772\tvalidation_1-rmse:4.81556\n",
            "[14]\tvalidation_0-rmse:2.71564\tvalidation_1-rmse:4.79774\n",
            "[15]\tvalidation_0-rmse:2.7006\tvalidation_1-rmse:4.78862\n",
            "[16]\tvalidation_0-rmse:2.68298\tvalidation_1-rmse:4.78075\n",
            "[17]\tvalidation_0-rmse:2.67176\tvalidation_1-rmse:4.76842\n",
            "[18]\tvalidation_0-rmse:2.66031\tvalidation_1-rmse:4.75871\n",
            "[19]\tvalidation_0-rmse:2.65081\tvalidation_1-rmse:4.74997\n",
            "[20]\tvalidation_0-rmse:2.63683\tvalidation_1-rmse:4.73949\n",
            "[21]\tvalidation_0-rmse:2.62684\tvalidation_1-rmse:4.728\n",
            "[22]\tvalidation_0-rmse:2.61802\tvalidation_1-rmse:4.72379\n",
            "[23]\tvalidation_0-rmse:2.60951\tvalidation_1-rmse:4.71469\n",
            "[24]\tvalidation_0-rmse:2.59971\tvalidation_1-rmse:4.7059\n",
            "[25]\tvalidation_0-rmse:2.58763\tvalidation_1-rmse:4.69925\n",
            "[26]\tvalidation_0-rmse:2.58065\tvalidation_1-rmse:4.69345\n",
            "[27]\tvalidation_0-rmse:2.57412\tvalidation_1-rmse:4.68836\n",
            "[28]\tvalidation_0-rmse:2.56957\tvalidation_1-rmse:4.68673\n",
            "[29]\tvalidation_0-rmse:2.56352\tvalidation_1-rmse:4.67841\n",
            "[30]\tvalidation_0-rmse:2.55961\tvalidation_1-rmse:4.67525\n",
            "[31]\tvalidation_0-rmse:2.55354\tvalidation_1-rmse:4.66973\n",
            "[32]\tvalidation_0-rmse:2.54757\tvalidation_1-rmse:4.66698\n",
            "[33]\tvalidation_0-rmse:2.54033\tvalidation_1-rmse:4.66395\n",
            "[34]\tvalidation_0-rmse:2.53626\tvalidation_1-rmse:4.66184\n",
            "[35]\tvalidation_0-rmse:2.53186\tvalidation_1-rmse:4.65523\n",
            "[36]\tvalidation_0-rmse:2.52822\tvalidation_1-rmse:4.6521\n",
            "[37]\tvalidation_0-rmse:2.52361\tvalidation_1-rmse:4.65408\n",
            "[38]\tvalidation_0-rmse:2.51766\tvalidation_1-rmse:4.64858\n",
            "[39]\tvalidation_0-rmse:2.51206\tvalidation_1-rmse:4.64655\n",
            "[40]\tvalidation_0-rmse:2.50827\tvalidation_1-rmse:4.64275\n",
            "[41]\tvalidation_0-rmse:2.50483\tvalidation_1-rmse:4.64042\n",
            "[42]\tvalidation_0-rmse:2.50029\tvalidation_1-rmse:4.63814\n",
            "[43]\tvalidation_0-rmse:2.49683\tvalidation_1-rmse:4.63607\n",
            "[44]\tvalidation_0-rmse:2.49092\tvalidation_1-rmse:4.63129\n",
            "[45]\tvalidation_0-rmse:2.48741\tvalidation_1-rmse:4.63173\n",
            "[46]\tvalidation_0-rmse:2.48396\tvalidation_1-rmse:4.627\n",
            "[47]\tvalidation_0-rmse:2.48069\tvalidation_1-rmse:4.62319\n",
            "[48]\tvalidation_0-rmse:2.47766\tvalidation_1-rmse:4.6212\n",
            "[49]\tvalidation_0-rmse:2.47437\tvalidation_1-rmse:4.61712\n",
            "[50]\tvalidation_0-rmse:2.47194\tvalidation_1-rmse:4.61536\n",
            "[51]\tvalidation_0-rmse:2.46804\tvalidation_1-rmse:4.6141\n",
            "[52]\tvalidation_0-rmse:2.46491\tvalidation_1-rmse:4.61137\n",
            "[53]\tvalidation_0-rmse:2.46257\tvalidation_1-rmse:4.60832\n",
            "[54]\tvalidation_0-rmse:2.46027\tvalidation_1-rmse:4.60513\n",
            "[55]\tvalidation_0-rmse:2.45749\tvalidation_1-rmse:4.60294\n",
            "[56]\tvalidation_0-rmse:2.45583\tvalidation_1-rmse:4.59958\n",
            "[57]\tvalidation_0-rmse:2.45371\tvalidation_1-rmse:4.5967\n",
            "[58]\tvalidation_0-rmse:2.45203\tvalidation_1-rmse:4.59683\n",
            "[59]\tvalidation_0-rmse:2.44879\tvalidation_1-rmse:4.59078\n",
            "[60]\tvalidation_0-rmse:2.44624\tvalidation_1-rmse:4.58692\n",
            "[61]\tvalidation_0-rmse:2.44217\tvalidation_1-rmse:4.57929\n",
            "[62]\tvalidation_0-rmse:2.43949\tvalidation_1-rmse:4.57546\n",
            "[63]\tvalidation_0-rmse:2.43724\tvalidation_1-rmse:4.57537\n",
            "[64]\tvalidation_0-rmse:2.43575\tvalidation_1-rmse:4.57283\n",
            "[65]\tvalidation_0-rmse:2.43321\tvalidation_1-rmse:4.57266\n",
            "[66]\tvalidation_0-rmse:2.43158\tvalidation_1-rmse:4.57084\n",
            "[67]\tvalidation_0-rmse:2.43009\tvalidation_1-rmse:4.56982\n",
            "[68]\tvalidation_0-rmse:2.4273\tvalidation_1-rmse:4.56571\n",
            "[69]\tvalidation_0-rmse:2.42509\tvalidation_1-rmse:4.56184\n",
            "[70]\tvalidation_0-rmse:2.42248\tvalidation_1-rmse:4.56165\n",
            "[71]\tvalidation_0-rmse:2.41961\tvalidation_1-rmse:4.561\n",
            "[72]\tvalidation_0-rmse:2.41804\tvalidation_1-rmse:4.55977\n",
            "[73]\tvalidation_0-rmse:2.41552\tvalidation_1-rmse:4.55725\n",
            "[74]\tvalidation_0-rmse:2.41327\tvalidation_1-rmse:4.5568\n",
            "[75]\tvalidation_0-rmse:2.41149\tvalidation_1-rmse:4.55372\n",
            "[76]\tvalidation_0-rmse:2.40966\tvalidation_1-rmse:4.55216\n",
            "[77]\tvalidation_0-rmse:2.40656\tvalidation_1-rmse:4.54708\n",
            "[78]\tvalidation_0-rmse:2.40514\tvalidation_1-rmse:4.54653\n",
            "[79]\tvalidation_0-rmse:2.40283\tvalidation_1-rmse:4.54512\n",
            "[80]\tvalidation_0-rmse:2.40116\tvalidation_1-rmse:4.54644\n",
            "[81]\tvalidation_0-rmse:2.39891\tvalidation_1-rmse:4.54727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4451b0bb7f8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#model.fit(X_train,y_train,eval_metric=\"rmse\",verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred_xgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9Mkm86Jl9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "17f07928-4a30-430a-f04d-eb3cb91aa511"
      },
      "source": [
        "# X=X_train.append(X_test, ignore_index = True) \n",
        "# y=np.append(y_train,y_test)\n",
        "# model.fit(X,y,eval_metric=\"rmse\",verbose=True,early_stopping_rounds = 10)\n",
        "final_pred_xgb = model.predict(test_final)\n",
        "\n",
        "submission['item_cnt_month']=final_pred_xgb.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('XGB_single2.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   ID  item_cnt_month\n",
            "0   0        0.482179\n",
            "1   1        0.262573\n",
            "2   2        0.968165\n",
            "3   3        0.281573\n",
            "4   4        3.835277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "doFQIuCyE_xl"
      },
      "source": [
        "The leaderboard score with this solution: 0.97607\n",
        "\n",
        "This is the best score obtained from a single model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs3dElAZHfXk",
        "colab_type": "text"
      },
      "source": [
        "# Ensembling the results with scheme (f) from the course\n",
        "\n",
        "Currently I have tried several approaches and their LB scores are mentioned as follows.\n",
        "\n",
        "\n",
        "\n",
        "1.   Linear Regression - 1.05954\n",
        "2.   Light GBM - 0.97665\n",
        "3.   Neural Network - 1.00741\n",
        "2.   Support Vector Regression- DID NOT WORK. HAVE TO DEBUG\n",
        "5.   K-Nearest Neighbour Regression- DID NOT WORK. HAVE TO DEBUG.\n",
        "6.   XGBoost - 0.97607\n",
        "\n",
        "In this section, I'm going to use 1, 2, 3, and 6 to generate the meta features.\n",
        "\n",
        "To validate on the second level features, I'm using the scheme f) provided in the course. Here, I'm generating meta features for date block nums 27, 28, 29, 30, 31, 32 to test the models on date block num 33. (This is similar to the scheme used for ensembling assignment). Then, meta features from 27 to 33 are used to train the final model and predict the values for date block num 34 with its own meta data. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZe7bKgcj2Up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64d7abb0-10ca-45b3-b2d5-9b2a2efe5a0e"
      },
      "source": [
        "#print(all_data.tail())\n",
        "# test_final.head()\n",
        "print(to_drop_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['trg', 's_mn', 'i_mn', 'date_block_num']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOd3eve9mALM",
        "colab_type": "text"
      },
      "source": [
        "##Generating meta features for the test set (date blocks 27 to 32)\n",
        "\n",
        "\n",
        "This takes a considerably a long time. Thus, the results are saved in a seperate file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob7-_CkMbXRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4be04ff2-4f8b-44b7-965e-f0357389cc2b"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "dates = all_data['date_block_num']\n",
        "dates_train = dates[dates <  33]\n",
        "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
        "\n",
        "# And here we create 2nd level feeature matrix, init it with zeros first\n",
        "X_train_level2 = np.zeros([y_train_level2.shape[0], 3])\n",
        "#X_train_level2 = np.zeros([test_final.shape[0], 2])\n",
        "\n",
        "# Now fill `X_train_level2` with metafeatures\n",
        "count=0\n",
        "lgb_params = {'feature_fraction': 0.75,'metric': 'rmse','nthread':1,'min_data_in_leaf': 2**7,'bagging_fraction': 0.75,\n",
        "              'learning_rate': 0.03,'objective': 'mse','bagging_seed': 2**7,'num_leaves': 2**7,'bagging_freq':1,'verbose':0}\n",
        "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
        "    \n",
        "    print(cur_block_num)\n",
        "    ## Setting up the train and test data for each round\n",
        "    X_train_temp = all_data.loc[dates <  cur_block_num].drop(to_drop_cols, axis=1)\n",
        "    X_test_temp =  all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis=1)\n",
        "\n",
        "    y_train_temp = all_data.loc[dates <  cur_block_num, 'trg'].values\n",
        "    y_test_temp =  all_data.loc[dates == cur_block_num, 'trg'].values\n",
        "    \n",
        "\n",
        "    #Starting the linear model\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(sc_X.fit_transform(X_train_temp.values), y_train_temp)\n",
        "    pred_lr_temp = lr.predict(sc_X.fit_transform(X_test_temp.values))\n",
        "    \n",
        "\n",
        "    #Starting the LGB model \n",
        "    model = lgb.train(lgb_params, lgb.Dataset(X_train_temp, label=y_train_temp), 100)\n",
        "    pred_lgb_temp = model.predict(X_test_temp)\n",
        "\n",
        "    #Starting the NN\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=(32,16), activation='relu', solver='adam', max_iter=50,early_stopping=True,verbose=1)\n",
        "    mlp.fit(sc_X.fit_transform(X_train_temp.values),y_train_temp)\n",
        "    pred_NN_temp = mlp.predict(sc_X.fit_transform(X_test_temp.values))\n",
        "\n",
        "\n",
        "    #np.append(X_train_level2,np.c_[pred_lr, pred_lgb],axis=1)\n",
        "    for i in range(len(pred_lr_temp)):\n",
        "        X_train_level2[count][0]=pred_lr_temp[i]\n",
        "        X_train_level2[count][1]=pred_lgb_temp[i]\n",
        "        X_train_level2[count][2]=pred_NN_temp[i]\n",
        "        count+=1\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n",
            "Iteration 1, loss = 2.76155994\n",
            "Validation score: 0.647420\n",
            "Iteration 2, loss = 2.63155724\n",
            "Validation score: 0.681180\n",
            "Iteration 3, loss = 2.49766541\n",
            "Validation score: 0.691660\n",
            "Iteration 4, loss = 2.44502316\n",
            "Validation score: 0.667130\n",
            "Iteration 5, loss = 2.37714337\n",
            "Validation score: 0.658975\n",
            "Iteration 6, loss = 2.34515500\n",
            "Validation score: 0.706489\n",
            "Iteration 7, loss = 2.33536410\n",
            "Validation score: 0.647151\n",
            "Iteration 8, loss = 2.28131417\n",
            "Validation score: 0.668704\n",
            "Iteration 9, loss = 2.28791176\n",
            "Validation score: 0.691058\n",
            "Iteration 10, loss = 2.24448202\n",
            "Validation score: 0.710607\n",
            "Iteration 11, loss = 2.22934749\n",
            "Validation score: 0.683495\n",
            "Iteration 12, loss = 2.19284138\n",
            "Validation score: 0.686751\n",
            "Iteration 13, loss = 2.19399282\n",
            "Validation score: 0.654837\n",
            "Iteration 14, loss = 2.22715472\n",
            "Validation score: 0.720622\n",
            "Iteration 15, loss = 2.20465877\n",
            "Validation score: 0.722899\n",
            "Iteration 16, loss = 2.16534573\n",
            "Validation score: 0.685484\n",
            "Iteration 17, loss = 2.19258144\n",
            "Validation score: 0.711609\n",
            "Iteration 18, loss = 2.18508693\n",
            "Validation score: 0.688273\n",
            "Iteration 19, loss = 2.11395665\n",
            "Validation score: 0.661400\n",
            "Iteration 20, loss = 2.18420700\n",
            "Validation score: 0.675085\n",
            "Iteration 21, loss = 2.14202978\n",
            "Validation score: 0.655967\n",
            "Iteration 22, loss = 2.16488114\n",
            "Validation score: 0.707126\n",
            "Iteration 23, loss = 2.11087450\n",
            "Validation score: 0.718827\n",
            "Iteration 24, loss = 2.09631085\n",
            "Validation score: 0.653548\n",
            "Iteration 25, loss = 2.13700786\n",
            "Validation score: 0.647980\n",
            "Iteration 26, loss = 2.13186553\n",
            "Validation score: 0.679610\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "28\n",
            "Iteration 1, loss = 3.09530512\n",
            "Validation score: 0.475066\n",
            "Iteration 2, loss = 2.98152754\n",
            "Validation score: 0.467481\n",
            "Iteration 3, loss = 2.86817211\n",
            "Validation score: 0.544292\n",
            "Iteration 4, loss = 2.85470810\n",
            "Validation score: 0.534732\n",
            "Iteration 5, loss = 2.83036173\n",
            "Validation score: 0.559033\n",
            "Iteration 6, loss = 2.75790120\n",
            "Validation score: 0.584246\n",
            "Iteration 7, loss = 2.71980837\n",
            "Validation score: 0.561186\n",
            "Iteration 8, loss = 2.72603575\n",
            "Validation score: 0.602102\n",
            "Iteration 9, loss = 2.73319313\n",
            "Validation score: 0.601063\n",
            "Iteration 10, loss = 2.67683170\n",
            "Validation score: 0.560659\n",
            "Iteration 11, loss = 2.62686023\n",
            "Validation score: 0.636075\n",
            "Iteration 12, loss = 2.59857079\n",
            "Validation score: 0.615713\n",
            "Iteration 13, loss = 2.64777723\n",
            "Validation score: 0.568256\n",
            "Iteration 14, loss = 2.61146366\n",
            "Validation score: 0.582438\n",
            "Iteration 15, loss = 2.60408592\n",
            "Validation score: 0.619843\n",
            "Iteration 16, loss = 2.55876025\n",
            "Validation score: 0.600552\n",
            "Iteration 17, loss = 2.58359085\n",
            "Validation score: 0.537810\n",
            "Iteration 18, loss = 2.58536477\n",
            "Validation score: 0.619162\n",
            "Iteration 19, loss = 2.58222532\n",
            "Validation score: 0.614455\n",
            "Iteration 20, loss = 2.52541244\n",
            "Validation score: 0.575500\n",
            "Iteration 21, loss = 2.58641931\n",
            "Validation score: 0.514247\n",
            "Iteration 22, loss = 2.56326256\n",
            "Validation score: 0.603056\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "29\n",
            "Iteration 1, loss = 3.01233417\n",
            "Validation score: 0.470248\n",
            "Iteration 2, loss = 2.90339223\n",
            "Validation score: 0.457800\n",
            "Iteration 3, loss = 2.86289600\n",
            "Validation score: 0.433918\n",
            "Iteration 4, loss = 2.75235225\n",
            "Validation score: 0.453289\n",
            "Iteration 5, loss = 2.80138626\n",
            "Validation score: 0.448833\n",
            "Iteration 6, loss = 2.69101593\n",
            "Validation score: 0.469881\n",
            "Iteration 7, loss = 2.71341245\n",
            "Validation score: 0.492796\n",
            "Iteration 8, loss = 2.66177213\n",
            "Validation score: 0.484075\n",
            "Iteration 9, loss = 2.61923892\n",
            "Validation score: 0.457579\n",
            "Iteration 10, loss = 2.56921643\n",
            "Validation score: 0.476161\n",
            "Iteration 11, loss = 2.63029585\n",
            "Validation score: 0.461855\n",
            "Iteration 12, loss = 2.53141391\n",
            "Validation score: 0.484721\n",
            "Iteration 13, loss = 2.54082532\n",
            "Validation score: 0.493162\n",
            "Iteration 14, loss = 2.53893569\n",
            "Validation score: 0.489497\n",
            "Iteration 15, loss = 2.45734591\n",
            "Validation score: 0.442693\n",
            "Iteration 16, loss = 2.45635307\n",
            "Validation score: 0.492867\n",
            "Iteration 17, loss = 2.46170651\n",
            "Validation score: 0.465972\n",
            "Iteration 18, loss = 2.43450764\n",
            "Validation score: 0.456691\n",
            "Iteration 19, loss = 2.49792172\n",
            "Validation score: 0.488501\n",
            "Iteration 20, loss = 2.49604492\n",
            "Validation score: 0.482084\n",
            "Iteration 21, loss = 2.48699653\n",
            "Validation score: 0.472281\n",
            "Iteration 22, loss = 2.46925831\n",
            "Validation score: 0.500752\n",
            "Iteration 23, loss = 2.43008709\n",
            "Validation score: 0.466197\n",
            "Iteration 24, loss = 2.40967099\n",
            "Validation score: 0.499178\n",
            "Iteration 25, loss = 2.44250691\n",
            "Validation score: 0.489507\n",
            "Iteration 26, loss = 2.45211296\n",
            "Validation score: 0.489993\n",
            "Iteration 27, loss = 2.43372382\n",
            "Validation score: 0.478538\n",
            "Iteration 28, loss = 2.46090411\n",
            "Validation score: 0.502575\n",
            "Iteration 29, loss = 2.43184676\n",
            "Validation score: 0.472967\n",
            "Iteration 30, loss = 2.46844590\n",
            "Validation score: 0.483591\n",
            "Iteration 31, loss = 2.41941847\n",
            "Validation score: 0.478175\n",
            "Iteration 32, loss = 2.42188236\n",
            "Validation score: 0.459361\n",
            "Iteration 33, loss = 2.42671594\n",
            "Validation score: 0.494246\n",
            "Iteration 34, loss = 2.39997427\n",
            "Validation score: 0.510228\n",
            "Iteration 35, loss = 2.41715926\n",
            "Validation score: 0.489664\n",
            "Iteration 36, loss = 2.36331382\n",
            "Validation score: 0.473224\n",
            "Iteration 37, loss = 2.40771044\n",
            "Validation score: 0.501743\n",
            "Iteration 38, loss = 2.39916195\n",
            "Validation score: 0.526902\n",
            "Iteration 39, loss = 2.38801266\n",
            "Validation score: 0.479937\n",
            "Iteration 40, loss = 2.37767834\n",
            "Validation score: 0.515941\n",
            "Iteration 41, loss = 2.38624572\n",
            "Validation score: 0.438938\n",
            "Iteration 42, loss = 2.40792133\n",
            "Validation score: 0.519565\n",
            "Iteration 43, loss = 2.36320772\n",
            "Validation score: 0.505513\n",
            "Iteration 44, loss = 2.37366258\n",
            "Validation score: 0.516729\n",
            "Iteration 45, loss = 2.38357030\n",
            "Validation score: 0.490360\n",
            "Iteration 46, loss = 2.35505918\n",
            "Validation score: 0.525855\n",
            "Iteration 47, loss = 2.36687986\n",
            "Validation score: 0.525222\n",
            "Iteration 48, loss = 2.40403243\n",
            "Validation score: 0.523882\n",
            "Iteration 49, loss = 2.34860257\n",
            "Validation score: 0.523427\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "30\n",
            "Iteration 1, loss = 3.07591358\n",
            "Validation score: 0.569949\n",
            "Iteration 2, loss = 3.02117153\n",
            "Validation score: 0.593085\n",
            "Iteration 3, loss = 2.91023250\n",
            "Validation score: 0.602295\n",
            "Iteration 4, loss = 2.85969784\n",
            "Validation score: 0.599704\n",
            "Iteration 5, loss = 2.86004251\n",
            "Validation score: 0.623863\n",
            "Iteration 6, loss = 2.79566135\n",
            "Validation score: 0.593407\n",
            "Iteration 7, loss = 2.78472882\n",
            "Validation score: 0.607526\n",
            "Iteration 8, loss = 2.79389862\n",
            "Validation score: 0.597712\n",
            "Iteration 9, loss = 2.79189823\n",
            "Validation score: 0.605051\n",
            "Iteration 10, loss = 2.73347100\n",
            "Validation score: 0.625742\n",
            "Iteration 11, loss = 2.76220141\n",
            "Validation score: 0.610285\n",
            "Iteration 12, loss = 2.76829370\n",
            "Validation score: 0.597275\n",
            "Iteration 13, loss = 2.73587629\n",
            "Validation score: 0.624755\n",
            "Iteration 14, loss = 2.67598095\n",
            "Validation score: 0.579877\n",
            "Iteration 15, loss = 2.64319660\n",
            "Validation score: 0.591557\n",
            "Iteration 16, loss = 2.65488300\n",
            "Validation score: 0.610174\n",
            "Iteration 17, loss = 2.67573762\n",
            "Validation score: 0.582754\n",
            "Iteration 18, loss = 2.68136781\n",
            "Validation score: 0.634948\n",
            "Iteration 19, loss = 2.65620416\n",
            "Validation score: 0.640864\n",
            "Iteration 20, loss = 2.62976403\n",
            "Validation score: 0.614886\n",
            "Iteration 21, loss = 2.62435021\n",
            "Validation score: 0.611889\n",
            "Iteration 22, loss = 2.63084075\n",
            "Validation score: 0.646248\n",
            "Iteration 23, loss = 2.60842185\n",
            "Validation score: 0.639443\n",
            "Iteration 24, loss = 2.60368814\n",
            "Validation score: 0.641487\n",
            "Iteration 25, loss = 2.58853577\n",
            "Validation score: 0.638258\n",
            "Iteration 26, loss = 2.57295199\n",
            "Validation score: 0.571241\n",
            "Iteration 27, loss = 2.60488146\n",
            "Validation score: 0.638084\n",
            "Iteration 28, loss = 2.62237496\n",
            "Validation score: 0.629536\n",
            "Iteration 29, loss = 2.58138885\n",
            "Validation score: 0.649318\n",
            "Iteration 30, loss = 2.58321903\n",
            "Validation score: 0.623033\n",
            "Iteration 31, loss = 2.57446880\n",
            "Validation score: 0.653455\n",
            "Iteration 32, loss = 2.53756570\n",
            "Validation score: 0.616587\n",
            "Iteration 33, loss = 2.58498813\n",
            "Validation score: 0.647492\n",
            "Iteration 34, loss = 2.59543945\n",
            "Validation score: 0.640513\n",
            "Iteration 35, loss = 2.54620714\n",
            "Validation score: 0.581901\n",
            "Iteration 36, loss = 2.52949773\n",
            "Validation score: 0.639935\n",
            "Iteration 37, loss = 2.52169225\n",
            "Validation score: 0.643674\n",
            "Iteration 38, loss = 2.59761062\n",
            "Validation score: 0.648613\n",
            "Iteration 39, loss = 2.54513372\n",
            "Validation score: 0.635662\n",
            "Iteration 40, loss = 2.58090192\n",
            "Validation score: 0.626403\n",
            "Iteration 41, loss = 2.57148862\n",
            "Validation score: 0.649891\n",
            "Iteration 42, loss = 2.57383309\n",
            "Validation score: 0.631780\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "31\n",
            "Iteration 1, loss = 3.01267241\n",
            "Validation score: 0.513833\n",
            "Iteration 2, loss = 2.84902477\n",
            "Validation score: 0.551034\n",
            "Iteration 3, loss = 2.75880901\n",
            "Validation score: 0.557182\n",
            "Iteration 4, loss = 2.73214096\n",
            "Validation score: 0.562145\n",
            "Iteration 5, loss = 2.73460735\n",
            "Validation score: 0.570771\n",
            "Iteration 6, loss = 2.71539473\n",
            "Validation score: 0.596354\n",
            "Iteration 7, loss = 2.68791255\n",
            "Validation score: 0.562536\n",
            "Iteration 8, loss = 2.61838186\n",
            "Validation score: 0.589024\n",
            "Iteration 9, loss = 2.54711803\n",
            "Validation score: 0.556905\n",
            "Iteration 10, loss = 2.57361023\n",
            "Validation score: 0.549623\n",
            "Iteration 11, loss = 2.59929081\n",
            "Validation score: 0.611563\n",
            "Iteration 12, loss = 2.56730441\n",
            "Validation score: 0.592019\n",
            "Iteration 13, loss = 2.56788264\n",
            "Validation score: 0.632538\n",
            "Iteration 14, loss = 2.55842205\n",
            "Validation score: 0.629686\n",
            "Iteration 15, loss = 2.48719680\n",
            "Validation score: 0.638719\n",
            "Iteration 16, loss = 2.51935256\n",
            "Validation score: 0.650631\n",
            "Iteration 17, loss = 2.48377916\n",
            "Validation score: 0.639648\n",
            "Iteration 18, loss = 2.50017235\n",
            "Validation score: 0.593907\n",
            "Iteration 19, loss = 2.48962788\n",
            "Validation score: 0.627739\n",
            "Iteration 20, loss = 2.49738078\n",
            "Validation score: 0.636749\n",
            "Iteration 21, loss = 2.47311336\n",
            "Validation score: 0.639841\n",
            "Iteration 22, loss = 2.45292897\n",
            "Validation score: 0.620185\n",
            "Iteration 23, loss = 2.45591525\n",
            "Validation score: 0.641326\n",
            "Iteration 24, loss = 2.42830611\n",
            "Validation score: 0.642940\n",
            "Iteration 25, loss = 2.40821397\n",
            "Validation score: 0.646006\n",
            "Iteration 26, loss = 2.43618687\n",
            "Validation score: 0.642599\n",
            "Iteration 27, loss = 2.42423441\n",
            "Validation score: 0.602514\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "32\n",
            "Iteration 1, loss = 2.87188176\n",
            "Validation score: 0.532960\n",
            "Iteration 2, loss = 2.72126349\n",
            "Validation score: 0.499301\n",
            "Iteration 3, loss = 2.70474028\n",
            "Validation score: 0.534948\n",
            "Iteration 4, loss = 2.70477503\n",
            "Validation score: 0.521240\n",
            "Iteration 5, loss = 2.65727079\n",
            "Validation score: 0.439821\n",
            "Iteration 6, loss = 2.65399115\n",
            "Validation score: 0.527606\n",
            "Iteration 7, loss = 2.59606842\n",
            "Validation score: 0.574635\n",
            "Iteration 8, loss = 2.58161649\n",
            "Validation score: 0.556507\n",
            "Iteration 9, loss = 2.58016064\n",
            "Validation score: 0.564379\n",
            "Iteration 10, loss = 2.50750853\n",
            "Validation score: 0.567087\n",
            "Iteration 11, loss = 2.49441365\n",
            "Validation score: 0.552585\n",
            "Iteration 12, loss = 2.48106824\n",
            "Validation score: 0.573671\n",
            "Iteration 13, loss = 2.46879459\n",
            "Validation score: 0.536844\n",
            "Iteration 14, loss = 2.46671601\n",
            "Validation score: 0.573832\n",
            "Iteration 15, loss = 2.46842658\n",
            "Validation score: 0.574371\n",
            "Iteration 16, loss = 2.43214840\n",
            "Validation score: 0.555351\n",
            "Iteration 17, loss = 2.43863452\n",
            "Validation score: 0.559867\n",
            "Iteration 18, loss = 2.40247449\n",
            "Validation score: 0.580194\n",
            "Iteration 19, loss = 2.39686595\n",
            "Validation score: 0.577139\n",
            "Iteration 20, loss = 2.36688671\n",
            "Validation score: 0.567590\n",
            "Iteration 21, loss = 2.35899120\n",
            "Validation score: 0.562523\n",
            "Iteration 22, loss = 2.36568653\n",
            "Validation score: 0.534131\n",
            "Iteration 23, loss = 2.36464564\n",
            "Validation score: 0.576553\n",
            "Iteration 24, loss = 2.37712637\n",
            "Validation score: 0.557535\n",
            "Iteration 25, loss = 2.35117873\n",
            "Validation score: 0.564063\n",
            "Iteration 26, loss = 2.36009362\n",
            "Validation score: 0.558932\n",
            "Iteration 27, loss = 2.36629674\n",
            "Validation score: 0.547265\n",
            "Iteration 28, loss = 2.34606534\n",
            "Validation score: 0.561595\n",
            "Iteration 29, loss = 2.35424405\n",
            "Validation score: 0.564901\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AM1jvlr8aeN",
        "colab_type": "text"
      },
      "source": [
        "##Generating the meta features for the test set (date block num=33)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOusLaTn8Zvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97122fa0-7fa0-42fe-97c7-3453451fe8e3"
      },
      "source": [
        " #Save the data for future use\n",
        " np.save('X_train_level2', X_train_level2) \n",
        " \n",
        " #Now generating the meta features for the final test set \n",
        "print(all_data.head())\n",
        "X_train_temp = all_data.loc[dates <  33].drop(to_drop_cols, axis=1)\n",
        "X_test_temp =  all_data.loc[dates == 33].drop(to_drop_cols, axis=1)\n",
        "\n",
        "y_train_temp = all_data.loc[dates <  33, 'trg'].values\n",
        "y_test_temp =  all_data.loc[dates == 33, 'trg'].values\n",
        "    \n",
        "\n",
        "    #Starting the linear model\n",
        "lr = LinearRegression()\n",
        "lr.fit(sc_X.fit_transform(X_train_temp.values), y_train_temp)\n",
        "pred_lr_temp = lr.predict(sc_X.fit_transform(X_test_temp.values))\n",
        "    \n",
        "\n",
        "    #Starting the LGB model \n",
        "model = lgb.train(lgb_params, lgb.Dataset(X_train_temp, label=y_train_temp), 100)\n",
        "pred_lgb_temp = model.predict(X_test_temp)\n",
        "\n",
        "#Starting the NN\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(32,16), activation='relu', solver='adam', max_iter=50,early_stopping=True,verbose=1)\n",
        "mlp.fit(sc_X.fit_transform(X_train_temp.values),y_train_temp)\n",
        "\n",
        "pred_NN_temp = mlp.predict(sc_X.fit_transform(X_test_temp.values))\n",
        "\n",
        "\n",
        "count=0\n",
        "X_test_level2 = np.c_[pred_lr_temp, pred_lgb_temp,pred_NN_temp] \n",
        "np.save('X_test_level2', X_test_level2)\n",
        "# for i in range(len(pred_lr_temp)):\n",
        "#   X_test_level2[count][0]=pred_lr_temp[i]\n",
        "#   X_test_level2[count][1]=pred_lgb_temp[i]\n",
        "#   count+=1   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   shop_id  item_id  date_block_num   trg    s_mn   i_mn  i_mn_l_1  s_mn_l_1  \\\n",
            "0       54    10297              12   4.0  8198.0   23.0      42.0   10055.0   \n",
            "1       54    10296              12   3.0  8198.0   17.0      24.0   10055.0   \n",
            "2       54    10298              12  14.0  8198.0  182.0     369.0   10055.0   \n",
            "3       54    10300              12   3.0  8198.0   26.0      54.0   10055.0   \n",
            "4       54    10284              12   1.0  8198.0    3.0       4.0   10055.0   \n",
            "\n",
            "   trg_l_1  i_mn_l_2  s_mn_l_2  trg_l_2  i_mn_l_3  s_mn_l_3  trg_l_3  \\\n",
            "0      3.0       2.0    7978.0      0.0       0.0       0.0      0.0   \n",
            "1      0.0       0.0       0.0      0.0       0.0       0.0      0.0   \n",
            "2     21.0    1309.0    7978.0    119.0     144.0    6676.0      7.0   \n",
            "3      1.0     361.0    7978.0     31.0      53.0    6676.0      0.0   \n",
            "4      0.0       3.0    7978.0      0.0       5.0    6676.0      0.0   \n",
            "\n",
            "   i_mn_l_4  s_mn_l_4  trg_l_4  i_mn_l_5  s_mn_l_5  trg_l_5  i_mn_l_6  \\\n",
            "0       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "1       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "2       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "3       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "4       3.0    7827.0      0.0      10.0    7792.0      0.0       9.0   \n",
            "\n",
            "   s_mn_l_6  trg_l_6  i_mn_l_12  s_mn_l_12  trg_l_12  item_category_id  \n",
            "0       0.0      0.0        0.0        0.0       0.0                37  \n",
            "1       0.0      0.0        0.0        0.0       0.0                38  \n",
            "2       0.0      0.0        0.0        0.0       0.0                40  \n",
            "3       0.0      0.0        0.0        0.0       0.0                37  \n",
            "4    7225.0      1.0        0.0        0.0       0.0                57  \n",
            "Iteration 1, loss = 3.44447463\n",
            "Validation score: 0.241407\n",
            "Iteration 2, loss = 3.35764621\n",
            "Validation score: 0.303909\n",
            "Iteration 3, loss = 3.20762499\n",
            "Validation score: 0.334475\n",
            "Iteration 4, loss = 3.30255755\n",
            "Validation score: 0.229339\n",
            "Iteration 5, loss = 3.22702056\n",
            "Validation score: 0.096859\n",
            "Iteration 6, loss = 3.16036251\n",
            "Validation score: 0.299412\n",
            "Iteration 7, loss = 3.15875265\n",
            "Validation score: 0.348545\n",
            "Iteration 8, loss = 3.08770184\n",
            "Validation score: 0.368533\n",
            "Iteration 9, loss = 3.04709541\n",
            "Validation score: 0.382327\n",
            "Iteration 10, loss = 3.04858571\n",
            "Validation score: 0.351964\n",
            "Iteration 11, loss = 3.01101624\n",
            "Validation score: 0.355283\n",
            "Iteration 12, loss = 2.98933303\n",
            "Validation score: 0.362513\n",
            "Iteration 13, loss = 2.88620314\n",
            "Validation score: 0.248211\n",
            "Iteration 14, loss = 2.86746701\n",
            "Validation score: 0.314283\n",
            "Iteration 15, loss = 2.81779190\n",
            "Validation score: 0.315416\n",
            "Iteration 16, loss = 2.85052437\n",
            "Validation score: 0.366694\n",
            "Iteration 17, loss = 2.83564191\n",
            "Validation score: 0.356663\n",
            "Iteration 18, loss = 2.77914821\n",
            "Validation score: 0.350282\n",
            "Iteration 19, loss = 2.74131495\n",
            "Validation score: 0.337173\n",
            "Iteration 20, loss = 2.78147872\n",
            "Validation score: 0.413878\n",
            "Iteration 21, loss = 2.74767787\n",
            "Validation score: 0.404739\n",
            "Iteration 22, loss = 2.68987461\n",
            "Validation score: 0.392835\n",
            "Iteration 23, loss = 2.69400865\n",
            "Validation score: 0.177684\n",
            "Iteration 24, loss = 2.65756658\n",
            "Validation score: 0.387872\n",
            "Iteration 25, loss = 2.62668925\n",
            "Validation score: 0.419073\n",
            "Iteration 26, loss = 2.70077570\n",
            "Validation score: 0.415449\n",
            "Iteration 27, loss = 2.62391319\n",
            "Validation score: 0.395784\n",
            "Iteration 28, loss = 2.60114578\n",
            "Validation score: 0.324016\n",
            "Iteration 29, loss = 2.52220794\n",
            "Validation score: 0.386074\n",
            "Iteration 30, loss = 2.54780115\n",
            "Validation score: 0.396758\n",
            "Iteration 31, loss = 2.56675960\n",
            "Validation score: 0.387495\n",
            "Iteration 32, loss = 2.52740206\n",
            "Validation score: 0.403570\n",
            "Iteration 33, loss = 2.58607078\n",
            "Validation score: 0.412448\n",
            "Iteration 34, loss = 2.48859769\n",
            "Validation score: 0.227859\n",
            "Iteration 35, loss = 2.45261501\n",
            "Validation score: 0.421036\n",
            "Iteration 36, loss = 2.54690966\n",
            "Validation score: 0.404267\n",
            "Iteration 37, loss = 2.49817334\n",
            "Validation score: 0.399549\n",
            "Iteration 38, loss = 2.49817542\n",
            "Validation score: 0.379709\n",
            "Iteration 39, loss = 2.48910217\n",
            "Validation score: 0.409729\n",
            "Iteration 40, loss = 2.43196365\n",
            "Validation score: 0.370762\n",
            "Iteration 41, loss = 2.65942251\n",
            "Validation score: 0.415141\n",
            "Iteration 42, loss = 2.51400872\n",
            "Validation score: 0.400995\n",
            "Iteration 43, loss = 2.43473548\n",
            "Validation score: 0.340479\n",
            "Iteration 44, loss = 2.41797732\n",
            "Validation score: 0.394361\n",
            "Iteration 45, loss = 2.52259500\n",
            "Validation score: 0.385111\n",
            "Iteration 46, loss = 2.43954251\n",
            "Validation score: 0.357738\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zLGAF70LOUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "266d9c3f-a943-4af4-f2f7-0af621348076"
      },
      "source": [
        " #Now generating the meta features for the final test set \n",
        "#print(test_final.head())\n",
        "X = all_data.drop(to_drop_cols, axis=1)\n",
        "y = np.append(y_train,y_test)\n",
        "\n",
        "\n",
        " #Strting the linear model\n",
        "lr = LinearRegression()\n",
        "lr.fit(sc_X.fit_transform(X.values), y)\n",
        "pred_lr_final = lr.predict(sc_X.fit_transform(test_final.values))\n",
        "\n",
        "model = lgb.train(lgb_params, lgb.Dataset(X, label=y), 100)\n",
        "pred_lgb_final = model.predict(test_final)\n",
        "\n",
        "#Starting the NN\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(32,16), activation='relu', solver='adam', max_iter=50,early_stopping=True,verbose=1)\n",
        "mlp.fit(sc_X.fit_transform(X.values),y)\n",
        "\n",
        "pred_NN_final = mlp.predict(sc_X.fit_transform(test_final.values))\n",
        "\n",
        "\n",
        "count=0\n",
        "#np.append(X_train_level2,np.c_[pred_lr, pred_lgb],axis=1)\n",
        "X_final_level2 = np.c_[pred_lr_final, pred_lgb_final,pred_NN_final] \n",
        "np.save('X_final_level2', X_final_level2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.68496770\n",
            "Validation score: 0.429310\n",
            "Iteration 2, loss = 3.58268557\n",
            "Validation score: 0.500573\n",
            "Iteration 3, loss = 3.44873211\n",
            "Validation score: 0.498720\n",
            "Iteration 4, loss = 3.45736261\n",
            "Validation score: 0.476497\n",
            "Iteration 5, loss = 3.38793787\n",
            "Validation score: 0.507301\n",
            "Iteration 6, loss = 3.33495824\n",
            "Validation score: 0.514307\n",
            "Iteration 7, loss = 3.34408860\n",
            "Validation score: 0.460664\n",
            "Iteration 8, loss = 3.32143402\n",
            "Validation score: 0.517834\n",
            "Iteration 9, loss = 3.27583305\n",
            "Validation score: 0.539496\n",
            "Iteration 10, loss = 3.27266152\n",
            "Validation score: 0.508022\n",
            "Iteration 11, loss = 3.26323881\n",
            "Validation score: 0.558047\n",
            "Iteration 12, loss = 3.21169960\n",
            "Validation score: 0.572773\n",
            "Iteration 13, loss = 3.25751741\n",
            "Validation score: 0.580670\n",
            "Iteration 14, loss = 3.14918857\n",
            "Validation score: 0.546941\n",
            "Iteration 15, loss = 3.15818940\n",
            "Validation score: 0.603670\n",
            "Iteration 16, loss = 3.07718826\n",
            "Validation score: 0.572489\n",
            "Iteration 17, loss = 3.09238727\n",
            "Validation score: 0.555669\n",
            "Iteration 18, loss = 3.06194179\n",
            "Validation score: 0.615196\n",
            "Iteration 19, loss = 3.09201173\n",
            "Validation score: 0.585246\n",
            "Iteration 20, loss = 3.03805671\n",
            "Validation score: 0.565350\n",
            "Iteration 21, loss = 3.10055197\n",
            "Validation score: 0.603647\n",
            "Iteration 22, loss = 3.10107243\n",
            "Validation score: 0.600606\n",
            "Iteration 23, loss = 3.02683649\n",
            "Validation score: 0.635996\n",
            "Iteration 24, loss = 2.96211812\n",
            "Validation score: 0.639035\n",
            "Iteration 25, loss = 3.02877267\n",
            "Validation score: 0.615052\n",
            "Iteration 26, loss = 2.98903111\n",
            "Validation score: 0.602018\n",
            "Iteration 27, loss = 3.00493461\n",
            "Validation score: 0.592823\n",
            "Iteration 28, loss = 2.92597287\n",
            "Validation score: 0.666531\n",
            "Iteration 29, loss = 2.91746747\n",
            "Validation score: 0.582063\n",
            "Iteration 30, loss = 2.87845899\n",
            "Validation score: 0.656440\n",
            "Iteration 31, loss = 2.87911073\n",
            "Validation score: 0.616060\n",
            "Iteration 32, loss = 2.88297740\n",
            "Validation score: 0.573421\n",
            "Iteration 33, loss = 2.82852605\n",
            "Validation score: 0.578643\n",
            "Iteration 34, loss = 2.88386872\n",
            "Validation score: 0.650806\n",
            "Iteration 35, loss = 2.83119317\n",
            "Validation score: 0.634310\n",
            "Iteration 36, loss = 2.78354104\n",
            "Validation score: 0.557582\n",
            "Iteration 37, loss = 2.80505522\n",
            "Validation score: 0.603125\n",
            "Iteration 38, loss = 2.81166114\n",
            "Validation score: 0.580547\n",
            "Iteration 39, loss = 2.88888416\n",
            "Validation score: 0.632801\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTgxU2_SV4P7",
        "colab_type": "text"
      },
      "source": [
        "The above codes generates the meta features by using LR, LGB, and NN. Since these takesa long time to run, those are saved as npy files. The following code snippets do the same for XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og0hCqSpzXSh",
        "colab_type": "text"
      },
      "source": [
        "##Generating XGBoost meta feature\n",
        "\n",
        "\n",
        "XGBoost met features are generated in this section. This section takes a lot of time to run. Thus, after each iteration, the obtained results are saved as numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhGOSLirzp1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d1b194-25b9-42d0-d261-c88c67ccc1bf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "dates = all_data['date_block_num']\n",
        "dates_train = dates[dates <  33]\n",
        "#for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
        "cur_block_num=33    \n",
        "print(cur_block_num)\n",
        "    ## Setting up the train and test data for each round\n",
        "X_train_temp = all_data.loc[dates <  cur_block_num].drop(to_drop_cols, axis=1)\n",
        "X_test_temp =  all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis=1)\n",
        "\n",
        "y_train_temp = all_data.loc[dates <  cur_block_num, 'trg'].values\n",
        "y_test_temp =  all_data.loc[dates == cur_block_num, 'trg'].values\n",
        "    \n",
        "model = XGBRegressor(max_depth=6,n_estimators=500,min_child_weight=40,colsample_bytree=0.8,subsample=0.8,eta=0.3,seed=42)\n",
        "\n",
        "model.fit(X_train,y_train,eval_metric=\"rmse\",eval_set=[(X_train_temp, y_train_temp),(X_test_temp, y_test_temp)],verbose=True,early_stopping_rounds = 6)\n",
        "pred_xgb=model.predict(X_test_temp)\n",
        "pickle.dump(model, open(\"xgb_final.pickle.dat\", \"wb\"))\n",
        "np.save('pred_xgb33', pred_xgb)\n",
        "pred_xgb=model.predict(test_final)    \n",
        "np.save('pred_xgb_final', pred_xgb)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "[18:36:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[18:36:33] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
            "[0]\tvalidation_0-rmse:3.41209\tvalidation_1-rmse:5.26514\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 6 rounds.\n",
            "[1]\tvalidation_0-rmse:3.30479\tvalidation_1-rmse:5.19146\n",
            "[2]\tvalidation_0-rmse:3.18394\tvalidation_1-rmse:5.11153\n",
            "[3]\tvalidation_0-rmse:3.09125\tvalidation_1-rmse:5.04677\n",
            "[4]\tvalidation_0-rmse:3.01616\tvalidation_1-rmse:4.99817\n",
            "[5]\tvalidation_0-rmse:2.94858\tvalidation_1-rmse:4.95324\n",
            "[6]\tvalidation_0-rmse:2.88748\tvalidation_1-rmse:4.9097\n",
            "[7]\tvalidation_0-rmse:2.83947\tvalidation_1-rmse:4.87392\n",
            "[8]\tvalidation_0-rmse:2.79589\tvalidation_1-rmse:4.84474\n",
            "[9]\tvalidation_0-rmse:2.76073\tvalidation_1-rmse:4.81122\n",
            "[10]\tvalidation_0-rmse:2.73453\tvalidation_1-rmse:4.79371\n",
            "[11]\tvalidation_0-rmse:2.70615\tvalidation_1-rmse:4.77634\n",
            "[12]\tvalidation_0-rmse:2.68004\tvalidation_1-rmse:4.75257\n",
            "[13]\tvalidation_0-rmse:2.6592\tvalidation_1-rmse:4.74102\n",
            "[14]\tvalidation_0-rmse:2.63592\tvalidation_1-rmse:4.72898\n",
            "[15]\tvalidation_0-rmse:2.61287\tvalidation_1-rmse:4.71583\n",
            "[16]\tvalidation_0-rmse:2.59706\tvalidation_1-rmse:4.70411\n",
            "[17]\tvalidation_0-rmse:2.58232\tvalidation_1-rmse:4.69068\n",
            "[18]\tvalidation_0-rmse:2.57\tvalidation_1-rmse:4.67099\n",
            "[19]\tvalidation_0-rmse:2.55962\tvalidation_1-rmse:4.66996\n",
            "[20]\tvalidation_0-rmse:2.54851\tvalidation_1-rmse:4.66064\n",
            "[21]\tvalidation_0-rmse:2.53694\tvalidation_1-rmse:4.65046\n",
            "[22]\tvalidation_0-rmse:2.52965\tvalidation_1-rmse:4.64698\n",
            "[23]\tvalidation_0-rmse:2.52343\tvalidation_1-rmse:4.64014\n",
            "[24]\tvalidation_0-rmse:2.5113\tvalidation_1-rmse:4.6319\n",
            "[25]\tvalidation_0-rmse:2.50047\tvalidation_1-rmse:4.63065\n",
            "[26]\tvalidation_0-rmse:2.49355\tvalidation_1-rmse:4.61995\n",
            "[27]\tvalidation_0-rmse:2.48931\tvalidation_1-rmse:4.61968\n",
            "[28]\tvalidation_0-rmse:2.4847\tvalidation_1-rmse:4.62111\n",
            "[29]\tvalidation_0-rmse:2.47985\tvalidation_1-rmse:4.61979\n",
            "[30]\tvalidation_0-rmse:2.47631\tvalidation_1-rmse:4.61941\n",
            "[31]\tvalidation_0-rmse:2.47218\tvalidation_1-rmse:4.62106\n",
            "[32]\tvalidation_0-rmse:2.46658\tvalidation_1-rmse:4.61925\n",
            "[33]\tvalidation_0-rmse:2.46298\tvalidation_1-rmse:4.61397\n",
            "[34]\tvalidation_0-rmse:2.45972\tvalidation_1-rmse:4.60976\n",
            "[35]\tvalidation_0-rmse:2.45697\tvalidation_1-rmse:4.6039\n",
            "[36]\tvalidation_0-rmse:2.45273\tvalidation_1-rmse:4.59321\n",
            "[37]\tvalidation_0-rmse:2.44667\tvalidation_1-rmse:4.59043\n",
            "[38]\tvalidation_0-rmse:2.44535\tvalidation_1-rmse:4.59002\n",
            "[39]\tvalidation_0-rmse:2.44168\tvalidation_1-rmse:4.581\n",
            "[40]\tvalidation_0-rmse:2.43552\tvalidation_1-rmse:4.58083\n",
            "[41]\tvalidation_0-rmse:2.43223\tvalidation_1-rmse:4.58202\n",
            "[42]\tvalidation_0-rmse:2.42741\tvalidation_1-rmse:4.58261\n",
            "[43]\tvalidation_0-rmse:2.42355\tvalidation_1-rmse:4.57527\n",
            "[44]\tvalidation_0-rmse:2.42063\tvalidation_1-rmse:4.57617\n",
            "[45]\tvalidation_0-rmse:2.41796\tvalidation_1-rmse:4.577\n",
            "[46]\tvalidation_0-rmse:2.41399\tvalidation_1-rmse:4.5776\n",
            "[47]\tvalidation_0-rmse:2.40994\tvalidation_1-rmse:4.5763\n",
            "[48]\tvalidation_0-rmse:2.40877\tvalidation_1-rmse:4.5735\n",
            "[49]\tvalidation_0-rmse:2.40769\tvalidation_1-rmse:4.57327\n",
            "[50]\tvalidation_0-rmse:2.40379\tvalidation_1-rmse:4.56423\n",
            "[51]\tvalidation_0-rmse:2.40135\tvalidation_1-rmse:4.56874\n",
            "[52]\tvalidation_0-rmse:2.39804\tvalidation_1-rmse:4.56875\n",
            "[53]\tvalidation_0-rmse:2.39589\tvalidation_1-rmse:4.56861\n",
            "[54]\tvalidation_0-rmse:2.39256\tvalidation_1-rmse:4.56922\n",
            "[55]\tvalidation_0-rmse:2.39204\tvalidation_1-rmse:4.56714\n",
            "[56]\tvalidation_0-rmse:2.39053\tvalidation_1-rmse:4.56805\n",
            "Stopping. Best iteration:\n",
            "[50]\tvalidation_0-rmse:2.40379\tvalidation_1-rmse:4.56423\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDSGIlKE320m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train_temp.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1DQ4b6SJCgb",
        "colab_type": "text"
      },
      "source": [
        "Since the above code takes more than 1 hour to run (for each date block num), the meta features from each date block num was saved. Now loading these files and generating the array of results for xgboost. At the same time adding these values to the X_test_level2, X_train_level2 and X_final_level2 arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DQU03hJqKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c33c25ae-8217-4693-c105-db219ae02004"
      },
      "source": [
        "XG_pred = np.load('pred_xgb27.npy')\n",
        "XG_28 = np.load('pred_xgb28.npy')\n",
        "XG_29 = np.load('pred_xgb29.npy')\n",
        "XG_30 = np.load('pred_xgb30.npy')\n",
        "XG_31 = np.load('pred_xgb31.npy')\n",
        "XG_32 = np.load('pred_xgb32.npy')\n",
        "XG_33 = np.load('pred_xgb33.npy')\n",
        "XG_final = np.load('pred_xgb_final.npy')\n",
        "XG_pred=np.append(XG_pred,XG_28)\n",
        "XG_pred=np.append(XG_pred,XG_29)\n",
        "XG_pred=np.append(XG_pred,XG_30)\n",
        "XG_pred=np.append(XG_pred,XG_31)\n",
        "XG_pred=np.append(XG_pred,XG_32)\n",
        "\n",
        "X_test_level2=np.load('X_test_level2.npy')\n",
        "X_train_level2=np.load('X_train_level2.npy')\n",
        "X_final_level2=np.load('X_final_level2.npy')\n",
        "\n",
        "print(XG_pred.shape)\n",
        "print(X_train_level2.shape)\n",
        "\n",
        "print(XG_33.shape)\n",
        "print(X_test_level2.shape)\n",
        "\n",
        "print(XG_final.shape)\n",
        "print(X_final_level2.shape)\n",
        "\n",
        "X_train_level2 = np.c_[X_train_level2,XG_pred] \n",
        "X_test_level2 = np.c_[X_test_level2,XG_33] \n",
        "X_final_level2 = np.c_[X_final_level2,XG_final] \n",
        "\n",
        "print(XG_pred.shape)\n",
        "print(X_train_level2.shape)\n",
        "\n",
        "print(XG_33.shape)\n",
        "print(X_test_level2.shape)\n",
        "\n",
        "print(XG_final.shape)\n",
        "print(X_final_level2.shape)\n",
        "\n",
        "np.save('X_train_level2', X_train_level2)\n",
        "np.save('X_test_level2', X_test_level2)\n",
        "np.save('X_final_level2', X_final_level2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1376192,)\n",
            "(1376192, 3)\n",
            "(238172,)\n",
            "(238172, 3)\n",
            "(214200,)\n",
            "(214200, 3)\n",
            "(1376192,)\n",
            "(1376192, 4)\n",
            "(238172,)\n",
            "(238172, 4)\n",
            "(214200,)\n",
            "(214200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nihPdh0t-e-u",
        "colab_type": "text"
      },
      "source": [
        "##Getting the final answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-5YT4rC-iAk",
        "colab_type": "text"
      },
      "source": [
        "### Simple linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjTe8AyO_zPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0a4c35b1-e6d8-44f7-db05-2ca3e7cc0e1e"
      },
      "source": [
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=32), 'trg'].values\n",
        "lr.fit(X_train_level2, y_test_temp)\n",
        "\n",
        "train_preds = lr.predict(X_train_level2)\n",
        "r2_train_stacking = r2_score(y_test_temp, train_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "test_preds = lr.predict(X_test_level2)\n",
        "r2_test_stacking = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
        "print('Test  R-squared for stacking is %f' % r2_test_stacking)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train R-squared for stacking is 0.287446\n",
            "Test  R-squared for stacking is 0.318761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlFmtrfTAQFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b0eb967b-4be4-4b43-cf2e-d32f51df6954"
      },
      "source": [
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=33), 'trg'].values\n",
        "\n",
        "X_final_train = np.append(X_train_level2,X_test_level2,axis=0)\n",
        "print(X_final_train.shape)\n",
        "#X_final_train=X_train_level2.append(X_test_level2, ignore_index = True) \n",
        "lr.fit(X_final_train, y_test_temp)\n",
        "\n",
        "final_preds = lr.predict(X_final_level2)\n",
        "\n",
        "\n",
        "submission['item_cnt_month']=final_preds.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('Linear_Ensemble_3.csv',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1614364, 3)\n",
            "   ID  item_cnt_month\n",
            "0   0        0.432216\n",
            "1   1        0.092727\n",
            "2   2        0.960536\n",
            "3   3        0.286704\n",
            "4   4        1.959579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5kN3LVJm-xF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_6QB13-9YAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGP372NeXjdu",
        "colab_type": "text"
      },
      "source": [
        "###Simple Neural network as the second level model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2szbcZ1xXoQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb543c36-144b-4f84-f57e-58a3e6b60384"
      },
      "source": [
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=32), 'trg'].values\n",
        "\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(8,8), activation='relu', solver='adam', max_iter=50,early_stopping=True,verbose=1)\n",
        "mlp.fit(X_train_level2, y_test_temp)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_preds = mlp.predict(X_train_level2)\n",
        "r2_train_stacking = r2_score(y_test_temp, train_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "test_preds = mlp.predict(X_test_level2)\n",
        "r2_test_stacking = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
        "print('Test  R-squared for stacking is %f' % r2_test_stacking)\n",
        "\n",
        "\n",
        "\n",
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=33), 'trg'].values\n",
        "\n",
        "X_final_train = np.append(X_train_level2,X_test_level2,axis=0)\n",
        "print(X_final_train.shape)\n",
        "#X_final_train=X_train_level2.append(X_test_level2, ignore_index = True) \n",
        "mlp.fit(X_final_train, y_test_temp)\n",
        "final_preds = mlp.predict(X_final_level2)\n",
        "\n",
        "submission['item_cnt_month']=final_preds.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('NN_Ensemble_4.csv',index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 6.41141396\n",
            "Validation score: 0.199550\n",
            "Iteration 2, loss = 5.99319951\n",
            "Validation score: 0.202615\n",
            "Iteration 3, loss = 6.06294467\n",
            "Validation score: 0.211581\n",
            "Iteration 4, loss = 6.04203789\n",
            "Validation score: 0.212820\n",
            "Iteration 5, loss = 5.98131149\n",
            "Validation score: 0.202402\n",
            "Iteration 6, loss = 6.01462970\n",
            "Validation score: 0.204761\n",
            "Iteration 7, loss = 5.96320448\n",
            "Validation score: 0.213334\n",
            "Iteration 8, loss = 6.00061646\n",
            "Validation score: 0.210754\n",
            "Iteration 9, loss = 5.97454970\n",
            "Validation score: 0.211910\n",
            "Iteration 10, loss = 6.01229372\n",
            "Validation score: 0.212061\n",
            "Iteration 11, loss = 5.90426363\n",
            "Validation score: 0.209004\n",
            "Iteration 12, loss = 5.89008943\n",
            "Validation score: 0.227163\n",
            "Iteration 13, loss = 5.96282778\n",
            "Validation score: 0.224626\n",
            "Iteration 14, loss = 5.94274803\n",
            "Validation score: 0.216839\n",
            "Iteration 15, loss = 5.92948549\n",
            "Validation score: 0.218362\n",
            "Iteration 16, loss = 5.93854717\n",
            "Validation score: 0.208707\n",
            "Iteration 17, loss = 5.92248458\n",
            "Validation score: 0.224546\n",
            "Iteration 18, loss = 5.92598256\n",
            "Validation score: 0.216275\n",
            "Iteration 19, loss = 5.95674091\n",
            "Validation score: 0.218868\n",
            "Iteration 20, loss = 5.91945570\n",
            "Validation score: 0.219316\n",
            "Iteration 21, loss = 5.86708167\n",
            "Validation score: 0.216034\n",
            "Iteration 22, loss = 5.91226098\n",
            "Validation score: 0.227587\n",
            "Iteration 23, loss = 5.88156826\n",
            "Validation score: 0.217814\n",
            "Iteration 24, loss = 5.88131434\n",
            "Validation score: 0.230672\n",
            "Iteration 25, loss = 5.85520478\n",
            "Validation score: 0.240226\n",
            "Iteration 26, loss = 5.90616497\n",
            "Validation score: 0.226920\n",
            "Iteration 27, loss = 5.87766718\n",
            "Validation score: 0.225102\n",
            "Iteration 28, loss = 5.76042486\n",
            "Validation score: 0.264036\n",
            "Iteration 29, loss = 6.06388352\n",
            "Validation score: 0.249909\n",
            "Iteration 30, loss = 5.88939182\n",
            "Validation score: 0.253418\n",
            "Iteration 31, loss = 5.95378500\n",
            "Validation score: 0.242609\n",
            "Iteration 32, loss = 5.83979449\n",
            "Validation score: 0.234341\n",
            "Iteration 33, loss = 5.87081696\n",
            "Validation score: 0.244388\n",
            "Iteration 34, loss = 5.77782841\n",
            "Validation score: 0.256250\n",
            "Iteration 35, loss = 5.79433332\n",
            "Validation score: 0.249284\n",
            "Iteration 36, loss = 5.79812871\n",
            "Validation score: 0.248629\n",
            "Iteration 37, loss = 5.87036577\n",
            "Validation score: 0.240951\n",
            "Iteration 38, loss = 5.74564193\n",
            "Validation score: 0.254002\n",
            "Iteration 39, loss = 5.76046749\n",
            "Validation score: 0.258824\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Train R-squared for stacking is 0.297380\n",
            "Test  R-squared for stacking is 0.290991\n",
            "(1614364, 3)\n",
            "Iteration 1, loss = 7.55567877\n",
            "Validation score: 0.479247\n",
            "Iteration 2, loss = 7.05588463\n",
            "Validation score: 0.484173\n",
            "Iteration 3, loss = 7.02622341\n",
            "Validation score: 0.397657\n",
            "Iteration 4, loss = 7.12875472\n",
            "Validation score: 0.457788\n",
            "Iteration 5, loss = 7.00340291\n",
            "Validation score: 0.465732\n",
            "Iteration 6, loss = 6.96699590\n",
            "Validation score: 0.409389\n",
            "Iteration 7, loss = 6.96135345\n",
            "Validation score: 0.484554\n",
            "Iteration 8, loss = 7.02924755\n",
            "Validation score: 0.508007\n",
            "Iteration 9, loss = 7.14257766\n",
            "Validation score: 0.516237\n",
            "Iteration 10, loss = 6.96097485\n",
            "Validation score: 0.508666\n",
            "Iteration 11, loss = 7.01636041\n",
            "Validation score: 0.501733\n",
            "Iteration 12, loss = 7.00247151\n",
            "Validation score: 0.422508\n",
            "Iteration 13, loss = 6.76390026\n",
            "Validation score: 0.417245\n",
            "Iteration 14, loss = 6.99121838\n",
            "Validation score: 0.510784\n",
            "Iteration 15, loss = 6.95713694\n",
            "Validation score: 0.503375\n",
            "Iteration 16, loss = 6.89410507\n",
            "Validation score: 0.454455\n",
            "Iteration 17, loss = 6.92184124\n",
            "Validation score: 0.517912\n",
            "Iteration 18, loss = 6.91749287\n",
            "Validation score: 0.508374\n",
            "Iteration 19, loss = 6.97184380\n",
            "Validation score: 0.522993\n",
            "Iteration 20, loss = 6.95335374\n",
            "Validation score: 0.511020\n",
            "Iteration 21, loss = 6.84735262\n",
            "Validation score: 0.529406\n",
            "Iteration 22, loss = 6.70618931\n",
            "Validation score: 0.457195\n",
            "Iteration 23, loss = 6.90107512\n",
            "Validation score: 0.546656\n",
            "Iteration 24, loss = 6.83031103\n",
            "Validation score: 0.564099\n",
            "Iteration 25, loss = 6.90231013\n",
            "Validation score: 0.547239\n",
            "Iteration 26, loss = 6.81410747\n",
            "Validation score: 0.554896\n",
            "Iteration 27, loss = 6.85067155\n",
            "Validation score: 0.530002\n",
            "Iteration 28, loss = 6.86846683\n",
            "Validation score: 0.550489\n",
            "Iteration 29, loss = 6.73175205\n",
            "Validation score: 0.557998\n",
            "Iteration 30, loss = 6.76029876\n",
            "Validation score: 0.535903\n",
            "Iteration 31, loss = 6.77001159\n",
            "Validation score: 0.569747\n",
            "Iteration 32, loss = 6.79844675\n",
            "Validation score: 0.562003\n",
            "Iteration 33, loss = 6.92252675\n",
            "Validation score: 0.538463\n",
            "Iteration 34, loss = 6.76233315\n",
            "Validation score: 0.569771\n",
            "Iteration 35, loss = 6.86963316\n",
            "Validation score: 0.564116\n",
            "Iteration 36, loss = 6.82064742\n",
            "Validation score: 0.597099\n",
            "Iteration 37, loss = 6.74003755\n",
            "Validation score: 0.529212\n",
            "Iteration 38, loss = 6.67902784\n",
            "Validation score: 0.338528\n",
            "Iteration 39, loss = 6.74510410\n",
            "Validation score: 0.500805\n",
            "Iteration 40, loss = 6.63152309\n",
            "Validation score: 0.602501\n",
            "Iteration 41, loss = 6.66752056\n",
            "Validation score: 0.583690\n",
            "Iteration 42, loss = 6.74758626\n",
            "Validation score: 0.532556\n",
            "Iteration 43, loss = 6.47565504\n",
            "Validation score: 0.480844\n",
            "Iteration 44, loss = 6.88257754\n",
            "Validation score: 0.536841\n",
            "Iteration 45, loss = 6.78623039\n",
            "Validation score: 0.584302\n",
            "Iteration 46, loss = 6.65131497\n",
            "Validation score: 0.598465\n",
            "Iteration 47, loss = 6.75560381\n",
            "Validation score: 0.558778\n",
            "Iteration 48, loss = 6.80766788\n",
            "Validation score: 0.591441\n",
            "Iteration 49, loss = 6.65550339\n",
            "Validation score: 0.555892\n",
            "Iteration 50, loss = 6.71016061\n",
            "Validation score: 0.625872\n",
            "   ID  item_cnt_month\n",
            "0   0        0.602129\n",
            "1   1        0.204041\n",
            "2   2        1.195575\n",
            "3   3        0.362626\n",
            "4   4        2.379164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7D9cBNldLVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e2cf4ab9-212f-4774-d7a2-715c2e8fa4ec"
      },
      "source": [
        "X_final_level2 = np.load('X_final_level2.npy') \n",
        "print(X_final_level2.shape)\n",
        "submission['item_cnt_month']=X_final_level2[:,2].clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('Linear_Ensemble_test3.csv',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(214200, 3)\n",
            "   ID  item_cnt_month\n",
            "0   0        0.347915\n",
            "1   1        3.510933\n",
            "2   2        0.621385\n",
            "3   3        0.137700\n",
            "4   4        0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEdKy_UxdZWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6d970a0b-dbb7-4259-8834-77d6b337a248"
      },
      "source": [
        "print(X_final_level2[:,2])\n",
        "print(X_final_level2[:,1])\n",
        "print(X_final_level2[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.34791472  3.51093324  0.62138483 ...  0.14671031 -0.05780269\n",
            " -0.15993974]\n",
            "[ 0.62197945  0.09947484  1.07775103 ... -0.02097045 -0.02184285\n",
            " -0.02184285]\n",
            "[-0.3057409   0.40513046  0.13444466 ...  0.32719403  0.01596999\n",
            " -0.06328963]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78LqRvVl5G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnVsbxZsLWzH",
        "colab_type": "text"
      },
      "source": [
        "#Quick Execution of Results\n",
        "\n",
        "\n",
        "\n",
        "This section loads the saved arrays to qucikly execute the ensembling results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9xi41LoMhDC",
        "colab_type": "text"
      },
      "source": [
        "##Single XGBoost Model\n",
        "\n",
        "\n",
        "First we load the XGBoost model that is saved. The LB score for this approach is 0.980943"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce3q8GroMgNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "15ce77d6-202e-48b0-d613-d4dab6fd9986"
      },
      "source": [
        "all_data=pd.read_csv('all_data.csv')\n",
        "test_final=pd.read_csv('test_final.csv')\n",
        "print(test_final.columns)\n",
        "print(test_final.head())\n",
        "#Load the model\n",
        "\n",
        "xgb_model = pickle.load(open(\"xgb_final.pickle.dat\", \"rb\"))\n",
        "\n",
        "final_pred_xgb = xgb_model.predict(test_final)\n",
        "\n",
        "submission['item_cnt_month']=final_pred_xgb.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('XGB_single_submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['shop_id', 'item_id', 'i_mn_l_1', 's_mn_l_1', 'trg_l_1', 'i_mn_l_2',\n",
            "       's_mn_l_2', 'trg_l_2', 'i_mn_l_3', 's_mn_l_3', 'trg_l_3', 'i_mn_l_4',\n",
            "       's_mn_l_4', 'trg_l_4', 'i_mn_l_5', 's_mn_l_5', 'trg_l_5', 'i_mn_l_6',\n",
            "       's_mn_l_6', 'trg_l_6', 'i_mn_l_12', 's_mn_l_12', 'trg_l_12',\n",
            "       'item_category_id'],\n",
            "      dtype='object')\n",
            "   shop_id  item_id  i_mn_l_1  s_mn_l_1  trg_l_1  i_mn_l_2  s_mn_l_2  trg_l_2  \\\n",
            "0        5     5037      25.0    1052.0      0.0     110.0    1092.0      1.0   \n",
            "1        5     5320       0.0       0.0      0.0       0.0       0.0      0.0   \n",
            "2        5     5233      42.0    1052.0      1.0      80.0    1092.0      3.0   \n",
            "3        5     5232      28.0    1052.0      0.0      48.0    1092.0      0.0   \n",
            "4        5     5268       0.0       0.0      0.0       0.0       0.0      0.0   \n",
            "\n",
            "   i_mn_l_3  s_mn_l_3  trg_l_3  i_mn_l_4  s_mn_l_4  trg_l_4  i_mn_l_5  \\\n",
            "0     119.0    1294.0      3.0      54.0     991.0      1.0     105.0   \n",
            "1       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "2     150.0    1294.0      1.0      37.0     991.0      0.0     119.0   \n",
            "3      65.0    1294.0      1.0       0.0       0.0      0.0       0.0   \n",
            "4       0.0       0.0      0.0       0.0       0.0      0.0       0.0   \n",
            "\n",
            "   s_mn_l_5  trg_l_5  i_mn_l_6  s_mn_l_6  trg_l_6  i_mn_l_12  s_mn_l_12  \\\n",
            "0     954.0      1.0      87.0    1012.0      1.0       65.0     1445.0   \n",
            "1       0.0      0.0       0.0       0.0      0.0        0.0        0.0   \n",
            "2     954.0      2.0      71.0    1012.0      3.0        0.0        0.0   \n",
            "3       0.0      0.0       0.0       0.0      0.0        0.0        0.0   \n",
            "4       0.0      0.0       0.0       0.0      0.0        0.0        0.0   \n",
            "\n",
            "   trg_l_12  item_category_id  \n",
            "0       1.0                19  \n",
            "1       0.0                55  \n",
            "2       0.0                19  \n",
            "3       0.0                23  \n",
            "4       0.0                20  \n",
            "[00:43:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "   ID  item_cnt_month\n",
            "0   0        0.418369\n",
            "1   1        0.269913\n",
            "2   2        0.961291\n",
            "3   3        0.311659\n",
            "4   4        3.146298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itq32lb1RMXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRwZWT9lRM-f",
        "colab_type": "text"
      },
      "source": [
        "##Ensembling by loading saved results\n",
        "\n",
        "\n",
        "\n",
        "First the saved second level features are loaded. Here X_final_level2 is the meat features for the test data set. X_test_level2 is the meta features for the validation data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr3D2b9jlzzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_level2=np.load('X_test_level2.npy')\n",
        "X_train_level2=np.load('X_train_level2.npy')\n",
        "X_final_level2=np.load('X_final_level2.npy')\n",
        "dates = all_data['date_block_num']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzemsYpbAn5J",
        "colab_type": "text"
      },
      "source": [
        "We currently have four meta features. In this section we look at the best meta feature selection to get the best result on the validataion data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNGw-UJaRUUP",
        "colab_type": "text"
      },
      "source": [
        "###Simple linear ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HgOSp0xRX5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "49028ce8-4311-4297-f751-f546af9a3356"
      },
      "source": [
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=32), 'trg'].values\n",
        "\n",
        "possible=[[1,2,3,0],[1,2,3],[1,2,0],[1,3,0],[2,3,0],[1,2],[1,3],[1,0],[3,2],[0,2],[3,0]]\n",
        "maxR2=0\n",
        "bestComb=0\n",
        "for ty in possible:\n",
        "  print(f'Testing for {ty}')\n",
        "  X_train_2=X_train_level2[:,ty]\n",
        "  X_test_2=X_test_level2[:,ty]\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(X_train_2, y_test_temp)\n",
        "\n",
        "  train_preds = lr.predict(X_train_2)\n",
        "  r2_train_stacking = r2_score(y_test_temp, train_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "  test_preds = lr.predict(X_test_2)\n",
        "  r2_test_stacking = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "  if r2_test_stacking>maxR2:\n",
        "    maxR2=r2_test_stacking\n",
        "    bestComb=ty\n",
        "  print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
        "  print('Test  R-squared for stacking is %f' % r2_test_stacking)\n",
        "\n",
        "\n",
        "\n",
        "print(f'Best combination is {bestComb}')\n",
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=33), 'trg'].values\n",
        "\n",
        "X_final_train = np.append(X_train_level2,X_test_level2,axis=0)\n",
        "#print(X_final_train[:,bestComb].shape)\n",
        "\n",
        "lr.fit(X_final_train[:,bestComb], y_test_temp)\n",
        "\n",
        "final_preds = lr.predict(X_final_level2[:,bestComb])\n",
        "\n",
        "\n",
        "submission['item_cnt_month']=final_preds.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('Linear_Ensemble_best.csv',index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing for [1, 2, 3, 0]\n",
            "Train R-squared for stacking is 0.688059\n",
            "Test  R-squared for stacking is 0.269071\n",
            "Testing for [1, 2, 3]\n",
            "Train R-squared for stacking is 0.687913\n",
            "Test  R-squared for stacking is 0.266699\n",
            "Testing for [1, 2, 0]\n",
            "Train R-squared for stacking is 0.287446\n",
            "Test  R-squared for stacking is 0.318761\n",
            "Testing for [1, 3, 0]\n",
            "Train R-squared for stacking is 0.687584\n",
            "Test  R-squared for stacking is 0.275300\n",
            "Testing for [2, 3, 0]\n",
            "Train R-squared for stacking is 0.687095\n",
            "Test  R-squared for stacking is 0.266608\n",
            "Testing for [1, 2]\n",
            "Train R-squared for stacking is 0.287362\n",
            "Test  R-squared for stacking is 0.318074\n",
            "Testing for [1, 3]\n",
            "Train R-squared for stacking is 0.686770\n",
            "Test  R-squared for stacking is 0.273831\n",
            "Testing for [1, 0]\n",
            "Train R-squared for stacking is 0.270163\n",
            "Test  R-squared for stacking is 0.285288\n",
            "Testing for [3, 2]\n",
            "Train R-squared for stacking is 0.687060\n",
            "Test  R-squared for stacking is 0.267695\n",
            "Testing for [0, 2]\n",
            "Train R-squared for stacking is 0.278803\n",
            "Test  R-squared for stacking is 0.307501\n",
            "Testing for [3, 0]\n",
            "Train R-squared for stacking is 0.686900\n",
            "Test  R-squared for stacking is 0.270996\n",
            "Best combination is [1, 2, 0]\n",
            "   ID  item_cnt_month\n",
            "0   0        0.432216\n",
            "1   1        0.092727\n",
            "2   2        0.960536\n",
            "3   3        0.286704\n",
            "4   4        1.959579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4kOvlWOW_j4",
        "colab_type": "text"
      },
      "source": [
        "The best meta features are 0,1, and 2 (corresponding to LR, LGB, and NN). The LB score for this is 0.97483"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM5ydnkdRYO5",
        "colab_type": "text"
      },
      "source": [
        "###Neural network ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXaeIDTmRa9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "abb67a62-dd05-4bd9-908e-387199e1b0d2"
      },
      "source": [
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=32), 'trg'].values\n",
        "\n",
        "\n",
        "possible=[[1,2,3,0],[1,2,3],[1,2,0],[1,3,0],[2,3,0],[1,2],[1,3],[1,0],[3,2],[0,2],[3,0]]\n",
        "#possible=[[1,2,3,0],[1,2,3],[1,2,0]]\n",
        "maxR2=0\n",
        "bestComb=0\n",
        "for ty in possible:\n",
        "  print(f'Testing for {ty}')\n",
        "  X_train_l2=X_train_level2[:,ty]\n",
        "  X_test_l2=X_test_level2[:,ty]\n",
        "  lr = LinearRegression()\n",
        "  mlp = MLPRegressor(hidden_layer_sizes=(8,8), activation='relu', solver='adam', max_iter=80,early_stopping=True,verbose=0)\n",
        "  mlp.fit(X_train_l2, y_test_temp)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  train_preds = mlp.predict(X_train_l2)\n",
        "  r2_train_stacking = r2_score(y_test_temp, train_preds)# YOUR CODE GOES HERE\n",
        "\n",
        "  test_preds = mlp.predict(X_test_l2)\n",
        "  r2_test_stacking = r2_score(y_test, test_preds)# YOUR CODE GOES HERE\n",
        "  if r2_test_stacking>maxR2:\n",
        "    maxR2=r2_test_stacking\n",
        "    bestComb=ty\n",
        "  print('Train R-squared for stacking is %f' % r2_train_stacking)\n",
        "  print('Test  R-squared for stacking is %f' % r2_test_stacking)\n",
        "\n",
        "\n",
        "\n",
        "print(f'Best combination is {bestComb}')\n",
        "y_test_temp =  all_data.loc[(27<=dates)&(dates<=33), 'trg'].values\n",
        "\n",
        "X_final_train = np.append(X_train_level2,X_test_level2,axis=0)\n",
        "\n",
        "#X_final_train=X_train_level2.append(X_test_level2, ignore_index = True) \n",
        "mlp.fit(X_final_train[:,bestComb], y_test_temp)\n",
        "final_preds = mlp.predict(X_final_level2[:,bestComb])\n",
        "\n",
        "submission['item_cnt_month']=final_preds.clip(0,20)\n",
        "print(submission.head())\n",
        "submission.to_csv('Neural_Network_Ensemble_best.csv',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing for [1, 2, 3, 0]\n",
            "Train R-squared for stacking is 0.686944\n",
            "Test  R-squared for stacking is 0.279066\n",
            "Testing for [1, 2, 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train R-squared for stacking is 0.703744\n",
            "Test  R-squared for stacking is 0.287465\n",
            "Testing for [1, 2, 0]\n",
            "Train R-squared for stacking is 0.290370\n",
            "Test  R-squared for stacking is 0.334793\n",
            "Testing for [1, 3, 0]\n",
            "Train R-squared for stacking is 0.690174\n",
            "Test  R-squared for stacking is 0.272060\n",
            "Testing for [2, 3, 0]\n",
            "Train R-squared for stacking is 0.688621\n",
            "Test  R-squared for stacking is 0.259912\n",
            "Testing for [1, 2]\n",
            "Train R-squared for stacking is 0.280925\n",
            "Test  R-squared for stacking is 0.274429\n",
            "Testing for [1, 3]\n",
            "Train R-squared for stacking is 0.694263\n",
            "Test  R-squared for stacking is 0.278571\n",
            "Testing for [1, 0]\n",
            "Train R-squared for stacking is 0.276053\n",
            "Test  R-squared for stacking is 0.280213\n",
            "Testing for [3, 2]\n",
            "Train R-squared for stacking is 0.688814\n",
            "Test  R-squared for stacking is 0.278086\n",
            "Testing for [0, 2]\n",
            "Train R-squared for stacking is 0.274222\n",
            "Test  R-squared for stacking is 0.282374\n",
            "Testing for [3, 0]\n",
            "Train R-squared for stacking is 0.682088\n",
            "Test  R-squared for stacking is 0.266350\n",
            "Best combination is [1, 2, 0]\n",
            "   ID  item_cnt_month\n",
            "0   0        0.388141\n",
            "1   1        0.181806\n",
            "2   2        0.960768\n",
            "3   3        0.228802\n",
            "4   4        2.061946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CGQTPHOgqMN",
        "colab_type": "text"
      },
      "source": [
        "The LB score for this result is 0.94125."
      ]
    }
  ]
}